# Configuration for Reaction-Diffusion dataset (Gray-Scott model)
# This uses the unified run_the_well_experiment.py script with GENERATED data source

# Basic experiment information
experiment_name: "reaction_diffusion_generated"
description: "FNO emulator for reaction-diffusion (Gray-Scott) dynamics with data generation"

# Emulator configuration
emulator_type: "the_well_fno"

# Data formatter
formatter_type: "default_channels_first"

# Model architecture parameters
model_params:
  modes1: 16              # Fourier modes in first dimension
  modes2: 16              # Fourier modes in second dimension
  hidden_channels: 128
  # width: 32               # Width of the FNO layers
  # n_blocks: 4             # Number of FNO blocks

# Simulator configuration for reaction-diffusion
# This triggers GENERATED data source type
simulator:
  type: "reaction_diffusion"
  n: 64                   # Spatial resolution (64x64 grid)
  T: 100.0                # Total simulation time
  dt: 1.0                 # Time step size
  L: 2.5                  # Domain size
  parameters_range:
    # Gray-Scott model parameters
    feed_rate: [0.02, 0.06]      # Feed rate (F)
    kill_rate: [0.045, 0.065]    # Kill rate (k)
  output_names: ["u", "v"]       # Chemical species U and V
  return_timeseries: true

# Data configuration - Generated from simulator
data:
  # No well_dataset_name - not a Well native dataset
  # No data_path - triggers GENERATED source type
  
  # Data generation
  n_train_samples: 200
  n_valid_samples: 20
  n_test_samples: 20
  random_seed: 42
  use_normalization: true
  
  # Dataset configuration
  dataset_type: "reaction_diffusion"
  n_steps_input: 4        # Number of input timesteps
  n_steps_output: 1       # Number of output timesteps (rollout length)
  batch_size: 4           # Batch size for training
  stride: 1               # Stride for sampling
  
  # Optional: channel indices (if you want to use only U or only V)
  # input_channel_idxs: [0]   # Only use U channel
  # output_channel_idxs: [0]  # Only predict U channel

# Trainer configuration
trainer:
  epochs: 100
  device: "cuda"
  
  optimizer_type: "adamw"
  optimizer_params:
    lr: 0.01             # Learning rate
    weight_decay: 0.0001
  
  lr_scheduler_type: "step_lr"
  lr_scheduler_params:
    step_size: 30
    gamma: 0.5
  
  loss_fn: "vrmse"        # VRMSE accounts for varying magnitudes over time
  
  val_frequency: 5
  checkpoint_frequency: 10
  rollout_val_frequency: 10
  max_rollout_steps: 100
  short_validation_length: 10
  make_rollout_videos: true
  
  # Teacher forcing schedule - helpful for reaction-diffusion
  enable_tf_schedule: true
  tf_params:
    start: 1.0            # Full teacher forcing at start
    end: 0.0              # No teacher forcing at end
    schedule_epochs: 50   # Decay over first 50 epochs
    schedule_type: "linear"
    mode: "mix"
    min_prob: 0.0
  
  # AMP settings (optional - for CUDA)
  enable_amp: false
  amp_type: null
  
  # Distributed training
  is_distributed: false
  checkpoint_path: null
  num_time_intervals: 1

# Paths
paths:
  output_dir: "./outputs/2025-10-22/reaction_diffusion_generated"
  model_save_path: "./outputs/reaction_diffusion_generated/artifacts/final_model.pt"
  # Optionally save generated data for reuse
  data_save_path: "./outputs/2025-10-22/data/reaction_diffusion_generated"
  save_format: "h5"       # or "pt" for PyTorch format

# Logging
log_level: "INFO"
verbose: true
