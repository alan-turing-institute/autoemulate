{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Simulate some data and fit an emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from autoemulate.experimental.simulations.projectile import ProjectileMultioutput\n",
    "from autoemulate.experimental.emulators.gaussian_process.exact import (\n",
    "    GaussianProcessExact,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_ranges = {\"c\": (-1.0, 1.0), \"v0\": (20.0, 100), \"angle\": (30.0, 60.0), \"h0\": (0.0, 10.0)}\n",
    "sim = ProjectileMultioutput()\n",
    "x = sim.sample_inputs(1000)\n",
    "y = sim.forward_batch(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GaussianProcessExact(x, y)\n",
    "gp.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "# Create test parameters WITHOUT in-place operations\n",
    "param_values = []\n",
    "for param in param_ranges.keys():\n",
    "    min_val, max_val = param_ranges[param]\n",
    "    param_values.append((min_val + max_val) / 2)\n",
    "\n",
    "test_params = torch.tensor([param_values], requires_grad=True)\n",
    "\n",
    "# Time forward pass\n",
    "start = time.time()\n",
    "output = gp.predict(test_params)\n",
    "forward_time = time.time() - start\n",
    "\n",
    "# Time backward pass (gradient computation)\n",
    "start = time.time()\n",
    "if hasattr(output, 'sum'):\n",
    "    loss = output.sum()\n",
    "    loss.backward()\n",
    "backward_time = time.time() - start\n",
    "\n",
    "print(f\"Forward pass: {forward_time:.4f}s\")\n",
    "print(f\"Backward pass: {backward_time:.4f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple HMC example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.experimental.calibration.hmc import MCMC_calibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with an \"observation\" that the GP has been trained on. \n",
    "\n",
    "Specifically, we will pretend we have N noisy experimental measurements. We should be able to recover the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1 # which simulated value to pick\n",
    "n_obs = 50\n",
    "noise_scale = 0.05 # set noise as some ratio of the observed value\n",
    "\n",
    "observations = {\n",
    "    \"distance\": y[idx, 0].repeat(n_obs) + torch.rand(n_obs) * noise_scale * y[idx, 0], \n",
    "    \"impact_velocity\": y[idx, 1].repeat(n_obs) + torch.rand(n_obs) * noise_scale * y[idx, 1]\n",
    "}\n",
    "observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test emulator speed\n",
    "import time\n",
    "parameter_range = {\"c\": (-1.0, 0.0), \"v0\": (20.0, 60), \"angle\": (30.0, 60.0), \"h0\": (0.0, 5.0)}\n",
    "\n",
    "test_params = torch.randn(100, len(parameter_range))\n",
    "start = time.time()\n",
    "predictions = gp.predict(test_params)\n",
    "print(f\"100 predictions took: {time.time() - start:.3f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the simulator parameter_range \n",
    "hmc = MCMC_calibration(gp, sim.parameters_range, observations, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run MCMC (note that below we have set the number of MCMC steps to a very low number, don't expect convergence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = hmc.run(\n",
    "    warmup_steps=100, \n",
    "    num_samples=100,\n",
    "    sampler='nuts',  # or 'nuts' or 'hmc'\n",
    "    # also init with x values matching \"observations\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned Pyro MCMC object has methods for accessing the generated samples (`mcmc.get_samples()`) or, as shown below, to get their summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting with Arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an option to turn the MCMC object into an Arviz object, which can be passed to any of their plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_data = hmc.to_arviz(mcmc, posterior_predictive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(az_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(az_data, kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ppc(az_data, kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr(az_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use sensitivity analysis and history matching to refine problem before running HMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MCMC_calibration` object has an option to provide a list of parameters to calibrate. A common approach is to select these based on results of `SensitivityAnalysis`.\n",
    "\n",
    "Similarly, the user provides parameter ranges from withing which to sample parameter values. This can be simply the range of the simulator. Alternatively, one can use `HistoryMatching` to reduce the parameter range and pass that to the `MCMC_calibration` instead. \n",
    "\n",
    "Below we demonstrate how to do both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.experimental.sensitivity_analysis import SensitivityAnalysis\n",
    "from autoemulate.experimental.calibration.history_matching import HistoryMatching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run sensitivity analysis and get top N parameters (here we just get the top 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = {\n",
    "        \"num_vars\": 2,\n",
    "        \"names\": sim.param_names,\n",
    "        \"bounds\": sim.param_bounds,\n",
    "    }\n",
    "\n",
    "sa = SensitivityAnalysis(gp, problem=problem)\n",
    "df = sa.run(\"sobol\")\n",
    "\n",
    "top_param = sa.top_n_sobol_params(df, 1)\n",
    "\n",
    "# the output is just a list of strings, this could be set by hand\n",
    "top_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run history matching and generate new parameter bounds from NROY samples (if get any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with some GP predictions\n",
    "x_new = sim.sample_inputs(20)\n",
    "output = gp.predict(torch.tensor(x_new, dtype=torch.float32))\n",
    "pred_means, pred_vars = (\n",
    "    output.mean.float().detach(),\n",
    "    output.variance.float().detach(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate NROY samples\n",
    "hm = HistoryMatching(\n",
    "    # take mean of observations and add noise\n",
    "    observations={k: [v.mean(), 10.0] for k,v in observations.items()},\n",
    "    threshold=5.0,\n",
    "    rank=2\n",
    ")\n",
    "implausability = hm.calculate_implausibility(pred_means, pred_vars)\n",
    "nroy_samples = hm.get_nroy(implausability, x_new)\n",
    "nroy_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newly generated range is slightly narrower than the range of the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new param bounds\n",
    "nroy_param_range = hm.generate_param_bounds(nroy_samples, param_names = sim.param_names)\n",
    "nroy_param_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pass results to the `MCMC_calibration` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmc_nroy = MCMC_calibration(\n",
    "    gp, \n",
    "    nroy_param_range if nroy_param_range is not None else sim.parameters_range, \n",
    "    observations, \n",
    "    10.0,\n",
    "    top_param\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_nroy = hmc_nroy.run(warmup_steps=10, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_nroy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
