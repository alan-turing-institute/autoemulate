{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Simulate some data and fit an emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "from autoemulate.experimental.simulations.projectile import Projectile, ProjectileMultioutput\n",
    "from autoemulate.experimental.emulators import GaussianProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = ProjectileMultioutput()\n",
    "x = sim.sample_inputs(100)\n",
    "y = sim.forward_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = GaussianProcess(x, y)\n",
    "gp.fit(x, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple HMC example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.experimental.calibration.bayes import BayesianCalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with an \"observation\" that the GP has been trained on. \n",
    "\n",
    "Specifically, we will pretend we have N noisy experimental measurements. We should be able to recover the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1 # which simulated value to pick\n",
    "n_obs = 10\n",
    "noise_scale = 0.05 # set noise as some ratio of the observed value\n",
    "\n",
    "observations = {\n",
    "    \"distance\": y[idx, 0].double().repeat(n_obs) + torch.rand(n_obs) * noise_scale * y[idx, 0], \n",
    "    \"impact_velocity\": y[idx, 1].repeat(n_obs) + torch.rand(n_obs) * noise_scale * y[idx, 1]\n",
    "}\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the simulator parameter_range \n",
    "bc = BayesianCalibration(gp, sim.parameters_range, observations, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run MCMC (note that below we have set the number of MCMC steps to a very low number, don't expect convergence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = bc.run_mcmc(\n",
    "    warmup_steps=10, \n",
    "    num_samples=100,\n",
    "    sampler='nuts',\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned Pyro MCMC object has methods for accessing the generated samples (`mcmc.get_samples()`) or, as shown below, to get their summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting with Arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an option to turn the MCMC object into an Arviz object, which can be passed to any of their plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_data = bc.to_arviz(mcmc, posterior_predictive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(az_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(az_data, kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ppc(az_data, kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr(az_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Use sensitivity analysis and history matching to refine problem before running HMC."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MCMC_calibration` object has an option to provide a list of parameters to calibrate. A common approach is to select these based on results of `SensitivityAnalysis`.\n",
    "\n",
    "Similarly, the user provides parameter ranges from withing which to sample parameter values. This can be simply the range of the simulator. Alternatively, one can use `HistoryMatching` to reduce the parameter range and pass that to the `MCMC_calibration` instead. \n",
    "\n",
    "Below we demonstrate how to do both."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.experimental.sensitivity_analysis import SensitivityAnalysis\n",
    "from autoemulate.experimental.calibration.history_matching import HistoryMatching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Run sensitivity analysis and get top N parameters (here we just get the top 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem = {\n",
    "        \"num_vars\": 2,\n",
    "        \"names\": sim.param_names,\n",
    "        \"bounds\": sim.param_bounds,\n",
    "    }\n",
    "\n",
    "sa = SensitivityAnalysis(gp, problem=problem)\n",
    "df = sa.run(\"sobol\")\n",
    "\n",
    "top_param = sa.top_n_sobol_params(df, 1)\n",
    "\n",
    "# the output is just a list of strings, this could be set by hand\n",
    "top_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Run history matching and generate new parameter bounds from NROY samples (if get any)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start with some GP predictions\n",
    "x_new = sim.sample_inputs(20)\n",
    "output = gp.predict(torch.tensor(x_new, dtype=torch.float32))\n",
    "pred_means, pred_vars = (\n",
    "    output.mean.float().detach(),\n",
    "    output.variance.float().detach(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate NROY samples\n",
    "hm = HistoryMatching(\n",
    "    # take mean of observations and add noise\n",
    "    observations={k: [v.mean(), 10.0] for k,v in observations.items()},\n",
    "    threshold=5.0,\n",
    "    rank=2\n",
    ")\n",
    "implausability = hm.calculate_implausibility(pred_means, pred_vars)\n",
    "nroy_samples = hm.get_nroy(implausability, x_new)\n",
    "nroy_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The newly generated range is slightly narrower than the range of the simulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get new param bounds\n",
    "nroy_param_range = hm.generate_param_bounds(nroy_samples, param_names = sim.param_names)\n",
    "nroy_param_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Pass results to the `MCMC_calibration` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc_nroy = BayesianCalibration(\n",
    "    gp, \n",
    "    nroy_param_range if nroy_param_range is not None else sim.parameters_range, \n",
    "    observations, \n",
    "    10.0,\n",
    "    top_param\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_nroy = bc_nroy.run_mcmc(warmup_steps=10, num_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_nroy.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
