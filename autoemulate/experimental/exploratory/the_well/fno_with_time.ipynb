{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76960de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set the default tensor type and device for all computations\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa43f79c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from the_well.data import WellDataset\n",
    "\n",
    "the_well = WellDataset(\n",
    "    well_base_path=\"../data/the_well/datasets\",\n",
    "    well_dataset_name=\"active_matter\",\n",
    "    well_split_name=\"test\",\n",
    "    n_steps_input=80,\n",
    "    n_steps_output=1,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200e3c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(the_well))\n",
    "x = batch[\"input_fields\"]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c1e1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 80*1*1*11).reshape(80, 1, 1, 11)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e9a1625",
   "metadata": {},
   "outputs": [],
   "source": [
    "x[2:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109aec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.unfold(0, 5, 2).permute(0, -1, 1, 2, 3)[1]\n",
    "# x.unfold(0, 5, 1).permute(0, -1, 1, 2, 3)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905dc9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "from autoemulate.core.types import TensorLike\n",
    "\n",
    "class AutoEmulateDataset(Dataset):\n",
    "    # Two steps:\n",
    "    # 1. Move methods from the specific subclass to the new base class\n",
    "    # 2. Make it look like the well (for __getitem__)\n",
    "    # TODO: add to performance issue #421\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        n_steps_input: int,\n",
    "        n_steps_output: int,\n",
    "        stride: int = 1,\n",
    "        input_channel_idxs: tuple[int, ...] | None = None,\n",
    "        output_channel_idxs: tuple[int, ...] | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path: Path to HDF5 file\n",
    "            t_in: Number of input timesteps\n",
    "            t_out: Number of output timesteps  \n",
    "            stride: Stride between sequences\n",
    "        \"\"\"\n",
    "        self.n_steps_input = n_steps_input\n",
    "        self.n_steps_output = n_steps_output\n",
    "        self.stride = stride\n",
    "        self.input_channel_idxs = input_channel_idxs # (0, 1, 2): predict from \n",
    "        self.output_channel_idxs = output_channel_idxs # (0,)\n",
    "        # (0,)\n",
    "        # (1, 2)\n",
    "        # (3, 4, 5, 6)\n",
    "        \n",
    "        # Load data\n",
    "        with h5py.File(data_path, 'r') as f:\n",
    "            # N: n_trajectories\n",
    "            self.data: TensorLike = f['data'][:]  # [N, T, W, H, C]\n",
    "            # TODO: since not supported into\n",
    "            self.constant_scalars: TensorLike = f['constant_scalars'][:] if 'constant_scalars' in f else None\n",
    "        \n",
    "        # Destructured here\n",
    "        self.n_trajectories, self.n_timesteps, self.width, self.height, self.n_channels = self.data.shape\n",
    "    \n",
    "    # TODO: is this required and what should it be\n",
    "    def __len__(self):\n",
    "        return self.n_trajectories\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # # Map flat index to (sample_idx, seq_idx)\n",
    "        trajectory_idx = idx\n",
    "        # trajectory_idx = idx // len(self)\n",
    "        # trajectory_idx = idx % len(self)\n",
    "        \n",
    "        # seq_idx = idx % self.sequences_per_sample\n",
    "        \n",
    "        # # Get start timestep for this sequence\n",
    "        # start_t = seq_idx * self.stride\n",
    "        # (0, 1, 2, 3, 4), (5,)\n",
    "        #    (0, 1, 2, 3, 4, 5,) -> (0, 1, 2, 3, 4), (5,)\n",
    "        # (1, 2, 3, 4, 5), (6,)\n",
    "        # data = self.data[sample_idx]\n",
    "        \n",
    "        # num_int_subtrajectories: (sequence_length - (n_step_inputs + n_step_outputs)) // stride) + 1\n",
    "        # 81 length for active matter\n",
    "        fields = (\n",
    "            self.data[trajectory_idx]\n",
    "            .unfold(0, self.n_steps_input + self.n_steps_output, self.stride)\n",
    "            .permute(0, -1, 1, 2, 3) # [num_int_subtrajectories, T_in + T_out, W, H, C]\n",
    "        )\n",
    "        input_fields = fields[:, :self.n_steps_input, ...]  # [num_int_subtrajectories, T_in, W, H, C]\n",
    "        output_fields = fields[:, self.n_steps_input:, ...]  # [num_int_subtrajectories, T_out, W, H, C]\n",
    "\n",
    "        constant_scalars = self.constant_scalars[trajectory_idx] if self.constant_scalars is not None else None\n",
    "        # return torch.FloatTensor(input_seq), torch.FloatTensor(output_seq)\n",
    "        return {\n",
    "            \"input_fields\": input_fields,\n",
    "            \"output_fields\": output_fields,\n",
    "            \"constant_scalars\": constant_scalars,\n",
    "            # Keys that are not in the well\n",
    "            # \"some_other_field\": ...\n",
    "            \"space_grid\": ...,\n",
    "            \"input_time_grid\": ...,\n",
    "            \"output_time_grid\": ...,\n",
    "        }\n",
    "    \n",
    "\n",
    "class MHDDataset(AutoEmulateDataset):\n",
    "    \"\"\"PyTorch Dataset for MHD data\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, t_in: int = 5, t_out: int = 10, stride: int = 1):\n",
    "        super().__init__(data_path, n_steps_input=t_in, n_steps_output=t_out, stride=stride)\n",
    "\n",
    "\n",
    "\n",
    "    class MyFNO():\n",
    "        def forward(self, batch):\n",
    "\n",
    "            # Implement the forward pass\n",
    "            x = batch[\"input_fields\"]\n",
    "            # constant_scalars = batch[\"constant_scalars\"]\n",
    "            constant_scalars = batch[\"constant_params\"]\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c2b108",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_fields\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b808a845",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "the_well.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b29dbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(the_well, batch_size=1)\n",
    "\n",
    "batch = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07ec112",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d9e3c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_fields\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d8dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"output_time_grid\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0f618a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "the_well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad88fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch[\"input_fields\"].shape, batch[\"output_fields\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3a4ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch[\"input_fields\"][0, 0, :, :, 0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fad4d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(batch[\"input_fields\"][0, 0, :, :, 0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a0b217e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralop.models import FNO\n",
    "\n",
    "model = FNO(\n",
    "    n_modes=(2, 16, 16),\n",
    "    hidden_channels=16,\n",
    "    in_channels=4,\n",
    "    out_channels=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e3f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.core.types import TensorLike\n",
    "from autoemulate.emulators.base import PyTorchBackend\n",
    "\n",
    "import torch\n",
    "\n",
    "def prepare_batch(sample, channels = (0,), with_constants=True, with_time=False):\n",
    "    # Get input fields, constant scalars and output fields\n",
    "    x = sample[\"input_fields\"][:, :, :, :, channels]  # [batch, time, height, width, len(channels)]\n",
    "    constant_scalars = sample[\"constant_scalars\"]  # [batch, n_constants]\n",
    "    y = sample[\"output_fields\"][:, :, :, :, channels]  # [batch, time, height, width, len(channels)]\n",
    "    \n",
    "    # Permute both x and y\n",
    "    x = x.permute(0, 4, 1, 2, 3)  # [batch, len(channels), time, height, width]\n",
    "    y = y.permute(0, 4, 1, 2, 3)  # [batch, len(channels), time, height, width]\n",
    "\n",
    "    # Only add constants to input, not output\n",
    "    if with_constants:\n",
    "        # Assign spatio-temporal dims to constants\n",
    "        time_window, height, width = x.shape[2], x.shape[3], x.shape[4]\n",
    "        n_constants = constant_scalars.shape[-1]\n",
    "\n",
    "        # Add spatio-temporal dims to constants\n",
    "        c_broadcast = constant_scalars.reshape(1, n_constants, 1, 1, 1).expand(1, n_constants, time_window, height, width)\n",
    "        \n",
    "        # Concatenate along channel dimension\n",
    "        x = torch.cat([x, c_broadcast], dim=1)\n",
    "\n",
    "    if not with_time:\n",
    "        # Take last time step for both input and output\n",
    "        return x[:, :, -1, :, :], y[:, :, -1, :, :]\n",
    "    # Otherwise include time\n",
    "    return x, y\n",
    "\n",
    "class FNOEmulator(PyTorchBackend):\n",
    "    def __init__(self, x, y, *args, **kwargs):\n",
    "        self.model = FNO(**kwargs)\n",
    "\n",
    "    def _fit(self, x: DataLoader, y: DataLoader):\n",
    "        channels = (0,)  # Which channel to use\n",
    "        print_shapes = False\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            # Prepare input with constants\n",
    "            x, y = prepare_batch(\n",
    "                batch, channels=channels, with_constants=True, with_time=True\n",
    "            )\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # Print shapes\n",
    "            if print_shapes:\n",
    "                print(x.shape, y.shape, y_pred.shape)\n",
    "            \n",
    "            # Get loss\n",
    "            # Take the first time idx as the next time step prediction\n",
    "            loss = self.loss_fn(y_pred[:, :, :1, ...], y)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            print(f\"sample {idx:5d}, loss: {loss.item():.5e}\")\n",
    "\n",
    "    def forward(self, x: TensorLike):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _predict(self, x, with_grad):\n",
    "        return super()._predict(x, with_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1619f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch[\"input_fields\"][:, :, :, :, :1]  # [batch, time, height, width, channels]\n",
    "y = batch[\"output_fields\"][:, :, :, :, :1]  # [batch, time, height, width, channels]\n",
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dd3f6e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.permute(0, 4, 1, 2, 3)  # Convert to [batch, channels, time, height, width]\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7251162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def prepare_batch(sample, channels = (0,), with_constants=True, with_time=False):\n",
    "    # Get input fields, constant scalars and output fields\n",
    "    x = sample[\"input_fields\"][:, :, :, :, channels]  # [batch, time, height, width, len(channels)]\n",
    "    constant_scalars = sample[\"constant_scalars\"]  # [batch, n_constants]\n",
    "    y = sample[\"output_fields\"][:, :, :, :, channels]  # [batch, time, height, width, len(channels)]\n",
    "    \n",
    "    # Permute both x and y\n",
    "    x = x.permute(0, 4, 1, 2, 3)  # [batch, len(channels), time, height, width]\n",
    "    y = y.permute(0, 4, 1, 2, 3)  # [batch, len(channels), time, height, width]\n",
    "\n",
    "    # Only add constants to input, not output\n",
    "    if with_constants:\n",
    "        # Assign spatio-temporal dims to constants\n",
    "        time_window, height, width = x.shape[2], x.shape[3], x.shape[4]\n",
    "        n_constants = constant_scalars.shape[-1]\n",
    "\n",
    "        # Add spatio-temporal dims to constants\n",
    "        c_broadcast = constant_scalars.reshape(1, n_constants, 1, 1, 1).expand(1, n_constants, time_window, height, width)\n",
    "        \n",
    "        # Concatenate along channel dimension\n",
    "        x = torch.cat([x, c_broadcast], dim=1)\n",
    "\n",
    "    if not with_time:\n",
    "        # Take last time step for both input and output\n",
    "        return x[:, :, -1, :, :], y[:, :, -1, :, :]\n",
    "    # Otherwise include time\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fe0825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without time\n",
    "x_with_constants, y = prepare_batch(batch, channels=(0,), with_time=True)\n",
    "print(f\"Concatenated x shape: {x_with_constants.shape}\")\n",
    "print(f\"Output y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fdc744",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With time\n",
    "x_with_constants, y = prepare_batch(batch, channels=(0,), with_time=True)\n",
    "print(f\"Concatenated x shape: {x_with_constants.shape}\")\n",
    "print(f\"Output y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03baebd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_batch(batch, with_time=True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7969df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pass through model\n",
    "model(prepare_batch(batch, with_time=True)[0]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7088d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "# Create new model\n",
    "model = FNO(\n",
    "    n_modes=(2, 16, 16),\n",
    "    hidden_channels=16,\n",
    "    in_channels=4,\n",
    "    out_channels=1,\n",
    ").to(device)\n",
    "\n",
    "# Explicitly set shuffle=False to ensure monotonic ordering\n",
    "train_loader = DataLoader(the_well, batch_size=1, shuffle=False)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-2,\n",
    "    # weight_decay=1e-4\n",
    ")\n",
    "\n",
    "loss_fn = MSELoss().to(device)\n",
    "channels = (0,)  # Which channel to use\n",
    "print_shapes = False\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    # Prepare input with constants\n",
    "    x, y = prepare_batch(batch, channels=channels, with_constants=True, with_time=True)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Print shapes\n",
    "    if print_shapes:\n",
    "        print(x.shape, y.shape, y_pred.shape)\n",
    "    \n",
    "    # Get loss\n",
    "    # Take the first time idx as the next time step prediction\n",
    "    loss = loss_fn(y_pred[:, :, :1, ...], y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"sample {idx:5d}, loss: {loss.item():.5e}\")\n",
    "\n",
    "    # Break after a few samples for testing\n",
    "    if idx >= 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78d02cc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
