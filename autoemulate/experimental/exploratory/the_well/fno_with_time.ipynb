{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "device = \"cpu\"\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Set the default tensor type and device for all computations\n",
    "torch.set_default_device(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from the_well.data import WellDataset\n",
    "\n",
    "the_well = WellDataset(\n",
    "    well_base_path=\"../data/the_well/datasets\",\n",
    "    well_dataset_name=\"active_matter\",\n",
    "    well_split_name=\"test\",\n",
    "    n_steps_input=5,\n",
    "    n_steps_output=1,\n",
    "    \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(the_well))\n",
    "x = batch[\"input_fields\"]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.arange(0, 80*1*1*11).reshape(80, 1, 1, 11)\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "from autoemulate.core.types import TensorLike\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "import h5py\n",
    "\n",
    "from autoemulate.core.types import TensorLike\n",
    "\n",
    "class AutoEmulateDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_path: str,\n",
    "        n_steps_input: int,\n",
    "        n_steps_output: int,\n",
    "        stride: int = 1,\n",
    "        input_channel_idxs: tuple[int, ...] | None = None,\n",
    "        output_channel_idxs: tuple[int, ...] | None = None,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data_path: Path to HDF5 file\n",
    "            t_in: Number of input timesteps\n",
    "            t_out: Number of output timesteps  \n",
    "            stride: Stride between sequences\n",
    "        \"\"\"\n",
    "        self.n_steps_input = n_steps_input\n",
    "        self.n_steps_output = n_steps_output\n",
    "        self.stride = stride\n",
    "        self.input_channel_idxs = input_channel_idxs\n",
    "        self.output_channel_idxs = output_channel_idxs\n",
    "        \n",
    "        # Load data\n",
    "        with h5py.File(data_path, 'r') as f:\n",
    "            self.data: TensorLike = torch.Tensor(f['data'][:])  # [N, T, W, H, C]\n",
    "            print(f\"Loaded data shape: {self.data.shape}\")\n",
    "            # TODO: add the constant scalars\n",
    "            self.constant_scalars: TensorLike = torch.Tensor(f['constant_scalars'][:]) if 'constant_scalars' in f else None # [N, C]\n",
    "            # TODO: add the constant fields\n",
    "            # self.constant_fields = torch.Tensor(f['data'][:])  # [N, W, H, C]\n",
    "        \n",
    "        # Destructured here\n",
    "        self.n_trajectories, self.n_timesteps, self.width, self.height, self.n_channels = self.data.shape\n",
    "        \n",
    "        # Pre-compute all subtrajectories for efficient indexing\n",
    "        self.all_input_fields = []\n",
    "        self.all_output_fields = []\n",
    "        self.all_constant_scalars = []\n",
    "        \n",
    "        for traj_idx in range(self.n_trajectories):\n",
    "            # Create subtrajectories for this trajectory\n",
    "            fields = (\n",
    "                self.data[traj_idx]\n",
    "                .unfold(0, self.n_steps_input + self.n_steps_output, self.stride)\n",
    "                .permute(0, -1, 1, 2, 3) # [num_subtrajectories, T_in + T_out, W, H, C]\n",
    "            )\n",
    "            \n",
    "            # Split into input and output\n",
    "            input_fields = fields[:, :self.n_steps_input, ...]  # [num_subtrajectories, T_in, W, H, C]\n",
    "            output_fields = fields[:, self.n_steps_input:, ...]  # [num_subtrajectories, T_out, W, H, C]\n",
    "            \n",
    "            # Store each subtrajectory separately\n",
    "            for sub_idx in range(input_fields.shape[0]):\n",
    "                self.all_input_fields.append(input_fields[sub_idx])  # [T_in, W, H, C]\n",
    "                self.all_output_fields.append(output_fields[sub_idx])  # [T_out, W, H, C]\n",
    "                \n",
    "                # Handle constant scalars\n",
    "                if self.constant_scalars is not None:\n",
    "                    self.all_constant_scalars.append(self.constant_scalars[traj_idx])\n",
    "                else:\n",
    "                    self.all_constant_scalars.append(torch.tensor([]))\n",
    "        \n",
    "        print(f\"Created {len(self.all_input_fields)} subtrajectory samples\")\n",
    "        print(f\"Each input sample shape: {self.all_input_fields[0].shape}\")\n",
    "        print(f\"Each output sample shape: {self.all_output_fields[0].shape}\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.all_input_fields)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            \"input_fields\": self.all_input_fields[idx],\n",
    "            \"output_fields\": self.all_output_fields[idx],\n",
    "            # \"constant_scalars\": self.all_constant_scalars[idx],\n",
    "            # TODO: add this\n",
    "            # \"constant_fields\": self.all_constant_fields[idx],\n",
    "        }\n",
    "    \n",
    "\n",
    "class MHDDataset(AutoEmulateDataset):\n",
    "    \"\"\"PyTorch Dataset for MHD data\"\"\"\n",
    "\n",
    "    def __init__(self, data_path: str, t_in: int = 5, t_out: int = 10, stride: int = 1):\n",
    "        super().__init__(data_path, n_steps_input=t_in, n_steps_output=t_out, stride=stride)\n",
    "\n",
    "\n",
    "class MyFNO():\n",
    "    def forward(self, batch):\n",
    "\n",
    "        # Implement the forward pass\n",
    "        x = batch[\"input_fields\"]\n",
    "        # constant_scalars = batch[\"constant_scalars\"]\n",
    "        constant_scalars = batch[\"constant_params\"]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(the_well, batch_size=1)\n",
    "\n",
    "batch = next(iter(train_loader))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"input_fields\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[\"output_time_grid\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch[\"input_fields\"].shape, batch[\"output_fields\"].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch[\"input_fields\"][0, 0, :, :, 0].shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.imshow(batch[\"input_fields\"][0, 0, :, :, 0].cpu())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example with fusion\n",
    "\n",
    "dataset = MHDDataset(\"../data/fusion/mhd_dataset.h5\")\n",
    "batch_fusion = next(iter(DataLoader(dataset)))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_fusion[\"input_fields\"].shape, batch_fusion[\"output_fields\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from neuralop.models import FNO\n",
    "\n",
    "model = FNO(\n",
    "    n_modes=(2, 16, 16),\n",
    "    hidden_channels=16,\n",
    "    in_channels=4,\n",
    "    out_channels=1,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.core.types import TensorLike\n",
    "from autoemulate.emulators.base import PyTorchBackend\n",
    "\n",
    "import torch\n",
    "\n",
    "def prepare_batch(sample, channels = (0,), with_constants=True, with_time=False):\n",
    "    # Get input fields, constant scalars and output fields\n",
    "    x = sample[\"input_fields\"][:, :, :, :, channels]  # [batch, time, height, width, len(channels)]\n",
    "    constant_scalars = sample[\"constant_scalars\"]  # [batch, n_constants]\n",
    "    y = sample[\"output_fields\"][:, :, :, :, channels]  # [batch, time, height, width, len(channels)]\n",
    "    \n",
    "    # Permute both x and y\n",
    "    x = x.permute(0, 4, 1, 2, 3)  # [batch, len(channels), time, height, width]\n",
    "    y = y.permute(0, 4, 1, 2, 3)  # [batch, len(channels), time, height, width]\n",
    "\n",
    "    # Only add constants to input, not output\n",
    "    if with_constants:\n",
    "        # Assign spatio-temporal dims to constants\n",
    "        time_window, height, width = x.shape[2], x.shape[3], x.shape[4]\n",
    "        n_constants = constant_scalars.shape[-1]\n",
    "\n",
    "        # Add spatio-temporal dims to constants\n",
    "        c_broadcast = constant_scalars.reshape(1, n_constants, 1, 1, 1).expand(1, n_constants, time_window, height, width)\n",
    "        \n",
    "        # Concatenate along channel dimension\n",
    "        x = torch.cat([x, c_broadcast], dim=1)\n",
    "\n",
    "    if not with_time:\n",
    "        # Take last time step for both input and output\n",
    "        return x[:, :, -1, :, :], y[:, :, -1, :, :]\n",
    "    # Otherwise include time\n",
    "    return x, y\n",
    "\n",
    "class FNOEmulator(PyTorchBackend):\n",
    "    def __init__(self, x, y, *args, **kwargs):\n",
    "        self.model = FNO(**kwargs)\n",
    "\n",
    "    def _fit(self, x: DataLoader, y: DataLoader):\n",
    "        channels = (0,)  # Which channel to use\n",
    "        print_shapes = False\n",
    "        for idx, batch in enumerate(train_loader):\n",
    "            # Prepare input with constants\n",
    "            x, y = prepare_batch(\n",
    "                batch, channels=channels, with_constants=True, with_time=True\n",
    "            )\n",
    "            \n",
    "            # Predictions\n",
    "            y_pred = model(x)\n",
    "\n",
    "            # Print shapes\n",
    "            if print_shapes:\n",
    "                print(x.shape, y.shape, y_pred.shape)\n",
    "            \n",
    "            # Get loss\n",
    "            # Take the first time idx as the next time step prediction\n",
    "            loss = self.loss_fn(y_pred[:, :, :1, ...], y)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            print(f\"sample {idx:5d}, loss: {loss.item():.5e}\")\n",
    "\n",
    "    def forward(self, x: TensorLike):\n",
    "        return self.model(x)\n",
    "    \n",
    "    def _predict(self, x, with_grad):\n",
    "        return super()._predict(x, with_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = batch[\"input_fields\"][:, :, :, :, :1]  # [batch, time, height, width, channels]\n",
    "y = batch[\"output_fields\"][:, :, :, :, :1]  # [batch, time, height, width, channels]\n",
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.permute(0, 4, 1, 2, 3)  # Convert to [batch, channels, time, height, width]\n",
    "x.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def prepare_batch(sample, channels = (0,), with_constants=True, with_time=False):\n",
    "    # Get input fields, constant scalars and output fields\n",
    "    x = sample[\"input_fields\"][:, :, :, :, channels]  # [batch, time, height, width, len(channels)]\n",
    "    constant_scalars = sample[\"constant_scalars\"]  # [batch, n_constants]\n",
    "    y = sample[\"output_fields\"][:, :, :, :, channels]  # [batch, time, height, width, len(channels)]\n",
    "    \n",
    "    # Permute both x and y\n",
    "    x = x.permute(0, 4, 1, 2, 3)  # [batch, len(channels), time, height, width]\n",
    "    y = y.permute(0, 4, 1, 2, 3)  # [batch, len(channels), time, height, width]\n",
    "\n",
    "    # Only add constants to input, not output\n",
    "    if with_constants:\n",
    "        # Assign spatio-temporal dims to constants\n",
    "        time_window, height, width = x.shape[2], x.shape[3], x.shape[4]\n",
    "        n_constants = constant_scalars.shape[-1]\n",
    "\n",
    "        # Add spatio-temporal dims to constants\n",
    "        c_broadcast = constant_scalars.reshape(1, n_constants, 1, 1, 1).expand(1, n_constants, time_window, height, width)\n",
    "        \n",
    "        # Concatenate along channel dimension\n",
    "        x = torch.cat([x, c_broadcast], dim=1)\n",
    "\n",
    "    if not with_time:\n",
    "        # Take last time step for both input and output\n",
    "        return x[:, :, -1, :, :], y[:, :, -1, :, :]\n",
    "    # Otherwise include time\n",
    "    return x, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without time\n",
    "x_with_constants, y = prepare_batch(batch, channels=(0,), with_time=True)\n",
    "print(f\"Concatenated x shape: {x_with_constants.shape}\")\n",
    "print(f\"Output y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# With time\n",
    "x_with_constants, y = prepare_batch(batch, channels=(0,), with_time=True)\n",
    "print(f\"Concatenated x shape: {x_with_constants.shape}\")\n",
    "print(f\"Output y shape: {y.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_batch(batch, with_time=True)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Pass through model\n",
    "model(prepare_batch(batch, with_time=True)[0]).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "from torch.nn import MSELoss\n",
    "\n",
    "# Create new model\n",
    "model = FNO(\n",
    "    n_modes=(2, 16, 16),\n",
    "    hidden_channels=16,\n",
    "    in_channels=4,\n",
    "    out_channels=1,\n",
    ").to(device)\n",
    "\n",
    "# Explicitly set shuffle=False to ensure monotonic ordering\n",
    "train_loader = DataLoader(the_well, batch_size=1, shuffle=False)\n",
    "\n",
    "optimizer = AdamW(\n",
    "    model.parameters(),\n",
    "    lr=1e-2,\n",
    "    # weight_decay=1e-4\n",
    ")\n",
    "\n",
    "loss_fn = MSELoss().to(device)\n",
    "channels = (0,)  # Which channel to use\n",
    "print_shapes = False\n",
    "for idx, batch in enumerate(train_loader):\n",
    "    # Prepare input with constants\n",
    "    x, y = prepare_batch(batch, channels=channels, with_constants=True, with_time=True)\n",
    "    \n",
    "    # Predictions\n",
    "    y_pred = model(x)\n",
    "\n",
    "    # Print shapes\n",
    "    if print_shapes:\n",
    "        print(x.shape, y.shape, y_pred.shape)\n",
    "    \n",
    "    # Get loss\n",
    "    # Take the first time idx as the next time step prediction\n",
    "    loss = loss_fn(y_pred[:, :, :1, ...], y)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    print(f\"sample {idx:5d}, loss: {loss.item():.5e}\")\n",
    "\n",
    "    # Break after a few samples for testing\n",
    "    if idx >= 100:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
