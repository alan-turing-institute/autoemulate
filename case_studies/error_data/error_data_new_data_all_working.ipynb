{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Simulate some data and fit an emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from autoemulate.emulators import GaussianProcess\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# well-behaved\n",
    "# df_x = pd.read_csv(\"./data/well_behaved_input.csv\")\n",
    "# df_y = pd.read_csv(\"./data/well_behaved_output.csv\")\n",
    "\n",
    "# All working parameters\n",
    "df_x = pd.read_csv(\"./data/AllWorkingParameters_input.csv\")\n",
    "df_y = pd.read_csv(\"./data/AllWorkingParameters_output.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_snr_db: adds gaussian noise to the output such that you match some signal-to-noise ratio\n",
    "# phase_offset: adds a phase offset to the output, rotates up to pi / 2\n",
    "# iq_amplitude_imbalance_db: -3, 3 (balance between real and imaginary parts, in dB)\n",
    "# - in-phase and quadrature amplitude imbalance\n",
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE: euclidean distance between the true signal and output\n",
    "# SER: symbol error rate, how many symbols are wrong in the output given nearest\n",
    "#   neighbor rounding given the scheme (8PSK, 16QAM, etc.)\n",
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.Tensor(df_x.to_numpy()).float()\n",
    "y = torch.Tensor(df_y.to_numpy()).float()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "torch.manual_seed(0)\n",
    "idx = torch.randperm(x.shape[0])\n",
    "# idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x[idx]\n",
    "y = y[idx, 1:]\n",
    "# y = y[idx, :1]\n",
    "x.shape, y.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train, y_train, x_test, y_test = x[:800], y[:800], x[800:1000], y[800:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(df_y.iloc[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.core.compare import AutoEmulate\n",
    "from autoemulate.emulators.gaussian_process.kernel import rbf, rbf_plus_constant\n",
    "from autoemulate.emulators.transformed.base import TransformedEmulator\n",
    "from autoemulate.transforms import StandardizeTransform, PCATransform\n",
    "\n",
    "em = TransformedEmulator(\n",
    "    x_train,\n",
    "    y_train,\n",
    "    model=GaussianProcess,\n",
    "    x_transforms=[StandardizeTransform()],\n",
    "    y_transforms=[StandardizeTransform()],\n",
    "    covar_module_fn=rbf_plus_constant,\n",
    ")\n",
    "\n",
    "em.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchmetrics import R2Score\n",
    "from autoemulate.core.model_selection import evaluate\n",
    "\n",
    "evaluate(em.predict(x_train), y_train, metric=R2Score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate(em.predict(x_test), y_test, metric=R2Score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.core.compare import AutoEmulate\n",
    "\n",
    "ae = AutoEmulate(x, y, models=[GaussianProcess], log_level=\"debug\", model_tuning=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(df_x.iloc[:, 0], df_y.iloc[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ae.plot(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.simulations.base import Simulator\n",
    "\n",
    "class ModError(Simulator):\n",
    "    def __init__(\n",
    "        self,\n",
    "        parameters_range: dict[str, tuple[float, float]],\n",
    "        output_names: list[str],\n",
    "        log_level: str = \"progress_bar\",\n",
    "    ):  \n",
    "        super().__init__(parameters_range, output_names, log_level=log_level)\n",
    "    \n",
    "    def _forward(self, x):\n",
    "        # Add function to go from parameters to output (SER)\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = ModError(parameters_range={\n",
    "    \"target_snr_db\": (-2.0, 30.0),\n",
    "    \"phase_offset\": (-1.0, 1.0),\n",
    "    \"iq_amplitude_imbalance_db\": (-3.0, 3.0)\n",
    "}, output_names=[\"SER\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_x.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.core.sensitivity_analysis import SensitivityAnalysis\n",
    "\n",
    "problem = {\n",
    "    \"num_vars\": len(df_x.columns),\n",
    "    \"names\": df_x.columns.tolist(),\n",
    "    \"bounds\": [\n",
    "        (df_x[col].min(), df_x[col].max()) for col in df_x.columns\n",
    "    ],\n",
    "}\n",
    "\n",
    "sa = SensitivityAnalysis(emulator=ae.best_result().model, problem=problem)\n",
    "\n",
    "df_sa = sa.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoemulate-error-quantification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_sa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sa.plot_sobol(df_sa)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simple HMC example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.calibration.bayes import BayesianCalibration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with an \"observation\" that the GP has been trained on. \n",
    "\n",
    "Specifically, we will pretend we have N noisy experimental measurements. We should be able to recover the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = -1 # which simulated value to pick\n",
    "n_obs = 100\n",
    "noise_scale = 0.05 # set noise as some ratio of the observed value\n",
    "\n",
    "# observations = {\"SER\": torch.Tensor([0.6]*100)}\n",
    "observations = {\"SER\": torch.Tensor([1.0]*100)}\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "parameters_range = dict(zip(problem[\"names\"], problem[\"bounds\"]))\n",
    "# use the simulator parameter_range \n",
    "bc = BayesianCalibration(em, parameters_range, observations, 10.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run MCMC (note that below we have set the number of MCMC steps to a very low number, don't expect convergence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = bc.run_mcmc(\n",
    "    warmup_steps=100, \n",
    "    num_samples=1000,\n",
    "    sampler='nuts',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The returned Pyro MCMC object has methods for accessing the generated samples (`mcmc.get_samples()`) or, as shown below, to get their summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Plotting with Arviz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have an option to turn the MCMC object into an Arviz object, which can be passed to any of their plotting function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arviz as az"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_data = bc.to_arviz(mcmc, posterior_predictive=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_trace(az_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_pair(az_data, kind='kde')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_ppc(az_data, kind='scatter')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az.plot_autocorr(az_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
