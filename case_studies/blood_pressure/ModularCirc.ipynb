{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient calibration workflow using AutoEmulate\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "## The Nagavi model\n",
    "\n",
    "<!-- <b>In this workflow we demonstrate the integration of a Cardiovascular simulator, Naghavi Model from ModularCirc in an end-to-end AutoEmulate workflow.</b>  -->\n",
    "\n",
    "The Nagavi lumped parameter model is a mathematical model of the human cardiovascular system, designed to simulate the dynamics of blood flow and pressure throughout the heart and circulatory system using lumped parameter modeling. \n",
    "A **lumped parameter model** simplifies the cardiovascular system by dividing it into compartments (or \"lumps\") such as:\n",
    "\n",
    "- Heart chambers (left and right atria and ventricles)\n",
    "- Major blood vessels (aorta, vena cava, pulmonary arteries and veins)\n",
    "- Systemic and pulmonary circulations\n",
    "\n",
    "Each compartment is modeled using analogies to electrical circuits:\n",
    "\n",
    "- Pressure ↔ Voltage\n",
    "- Flow ↔ Current\n",
    "- Resistance ↔ Vascular resistance (R\\)\n",
    "- Compliance ↔ Vessel elasticity or capacitance (C\\)\n",
    "- Inertance ↔ Blood inertia (L)\n",
    "\n",
    "This approach allows simulation of the time-dependent relationships between pressure, volume, and flow rate across the entire cardiovascular system using ordinary differential equations (ODEs).\n",
    "\n",
    "The Nagavi lumped parameter model is a mathematical model of the human cardiovascular system, designed to simulate the dynamics of blood flow and pressure throughout the heart and circulatory system using lumped parameter modeling. \n",
    "A **lumped parameter model** simplifies the cardiovascular system by dividing it into compartments (or \"lumps\") such as:\n",
    "\n",
    "## Patient calibration workflow\n",
    "\n",
    "In this tutorial, we present a three-stage workflow for calibrating the Nagavi model to patient-specific clinical data using AutoEmulate. The process has the following stages:\n",
    "\n",
    "- First we perform a global sensitivity analysis, which identifies the most influential parameters affecting model outputs and reduces the dimensionality of the calibration problem. \n",
    "- Next, we apply history matching, a sequential uncertainty quantification technique that uses emulators to efficiently rule out implausible regions of the parameter space based on observed patient data. This results in a restricted, plausible region—known as the NROY (Not Ruled Out Yet) space—where parameters are consistent with the clinical measurements within acceptable uncertainty bounds. \n",
    "- Finally, we perform Bayesian inference within this NROY region to estimate the full posterior distribution of the remaining parameters, capturing the most likely values and their associated uncertainty. \n",
    "\n",
    "### Global sensitivity analysis\n",
    "\n",
    "The Nagavi model has 16 parameters which makes individual patient calibration challenging. To address this we use a emulator-based global sensitivity analysis to quantify the influence each parameter on features derived from left ventricle artery pressure. This approach reduces the parameters that will be used in model personalization from 16 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:46:18.076147Z",
     "start_time": "2025-07-30T13:46:15.450178Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up simulator and generate data\n",
    "\n",
    "For this tutorial we use `ModularCirc` a package that providse a framework for building 0D models and simulating cardiovascular flow and mechanics. The `NaghaviSimulator` simulates pressure traces, we then choose to output summary statistics for each of the simulated traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:46:21.000250Z",
     "start_time": "2025-07-30T13:46:18.062885Z"
    }
   },
   "outputs": [],
   "source": [
    "from cardiac_simulator import NaghaviSimulator\n",
    "\n",
    "simulator = NaghaviSimulator(\n",
    "    output_variables=['lv.P_i', 'lv.P_o'],  # Only the ones you're interested in\n",
    "    n_cycles=300, \n",
    "    dt=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulator comes with predefined input parameters ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:46:21.015598Z",
     "start_time": "2025-07-30T13:46:20.992463Z"
    }
   },
   "outputs": [],
   "source": [
    "simulator.parameters_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample from those using Latin Hypercube Sampling to generate data to train the emulator with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:46:21.636701Z",
     "start_time": "2025-07-30T13:46:21.004800Z"
    }
   },
   "outputs": [],
   "source": [
    "N_samples = 1024\n",
    "x = simulator.sample_inputs(N_samples,random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use the simulator to generate predictions for the sampled parameters. Alternatively, for convenience. we can load already simulated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:46:21.653686Z",
     "start_time": "2025-07-30T13:46:21.636549Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "save = True\n",
    "\n",
    "if not os.path.exists(f'simulator_results_{N_samples}.csv'):\n",
    "    # Run batch simulations with the samples generated in Cell 1\n",
    "    y, x = simulator.forward_batch_skip_failures(x)\n",
    "    \n",
    "    # Convert results to DataFrame for analysis\n",
    "    results_df = pd.DataFrame(y)\n",
    "    inputs_df = pd.DataFrame(x)\n",
    "    \n",
    "    if save:\n",
    "        # Save the results to a CSV file\n",
    "        results_df.to_csv(f'simulator_results_{N_samples}.csv', index=False)\n",
    "        inputs_df.to_csv(f'simulator_inputs_{N_samples}.csv', index=False)\n",
    "\n",
    "else:\n",
    "    # Read the results from the CSV file\n",
    "    results_df = pd.read_csv(f'simulator_results_{N_samples}.csv')\n",
    "    inputs_df = pd.read_csv(f'simulator_inputs_{N_samples}.csv')\n",
    "\n",
    "    y = torch.tensor(results_df.to_numpy())\n",
    "    x = torch.tensor(inputs_df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the output summary variables we've simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:46:21.657980Z",
     "start_time": "2025-07-30T13:46:21.649372Z"
    }
   },
   "outputs": [],
   "source": [
    "simulator.output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train emulator with AutoEmulate\n",
    " \n",
    "To perform sensitivity analysis efficiently, we first need to construct an emulator—a fast, surrogate model that approximates the output of the full simulator. The simulated inputs and outputs from the cell above are  used to train the emulator, in this case we choose to use neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:30.458438Z",
     "start_time": "2025-07-30T13:46:21.652062Z"
    }
   },
   "outputs": [],
   "source": [
    "from autoemulate.experimental.compare import AutoEmulate\n",
    "\n",
    "from autoemulate.experimental.emulators.nn.mlp import MLP\n",
    "\n",
    "ae = AutoEmulate(\n",
    "    x, \n",
    "    y, \n",
    "    models=[MLP],  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:30.531852Z",
     "start_time": "2025-07-30T13:48:30.443619Z"
    }
   },
   "outputs": [],
   "source": [
    "ae.summarise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the best performing emulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:30.532778Z",
     "start_time": "2025-07-30T13:48:30.453540Z"
    }
   },
   "outputs": [],
   "source": [
    "model = ae.best_result().model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:33.398339Z",
     "start_time": "2025-07-30T13:48:32.800655Z"
    }
   },
   "outputs": [],
   "source": [
    "#### Run Sensitivity Analysis \n",
    "\n",
    "The emulator trained above can predict model outputs rapidly across the entire parameter space, allowing us to estimate global sensitivity measures like Sobol’ indices or Morris elementary effects without repeatedly calling the full simulator. This approach enables scalable and accurate sensitivity analysis, especially in high-dimensional or computationally intensive settings.\n",
    "\n",
    "Here we use AutoEmulate to perform sensitivity analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:30.728362Z",
     "start_time": "2025-07-30T13:48:30.457987Z"
    }
   },
   "outputs": [],
   "source": [
    "from autoemulate.experimental.sensitivity_analysis import SensitivityAnalysis\n",
    "\n",
    "# Define the problem dictionary for Sobol sensitivity analysis\n",
    "problem = {\n",
    "    'num_vars': simulator.in_dim,\n",
    "    'names': simulator.param_names,\n",
    "    'bounds': simulator.param_bounds\n",
    "}\n",
    "\n",
    "si = SensitivityAnalysis(model, problem=problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:32.805615Z",
     "start_time": "2025-07-30T13:48:30.506570Z"
    }
   },
   "outputs": [],
   "source": [
    "si_df = si.run(method='sobol')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:33.398339Z",
     "start_time": "2025-07-30T13:48:32.800655Z"
    }
   },
   "outputs": [],
   "source": [
    "si.plot_sobol(si_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:33.750611Z",
     "start_time": "2025-07-30T13:48:33.397066Z"
    }
   },
   "outputs": [],
   "source": [
    "si.plot_sa_heatmap(si_df, index='ST', cmap='coolwarm', normalize=True, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the top 5 parameters that have the biggest influcence on the pressure wave summary statistics extracted from the Nagavi Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:33.764591Z",
     "start_time": "2025-07-30T13:48:33.526281Z"
    }
   },
   "outputs": [],
   "source": [
    "top_parameters_sa = si.top_n_sobol_params(si_df,top_n=5)\n",
    "top_parameters_sa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters that are found to be less influential are fixed to a mid point value within its range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:33.765734Z",
     "start_time": "2025-07-30T13:48:33.527664Z"
    }
   },
   "outputs": [],
   "source": [
    "updated_range = {}\n",
    "for param_name, (min_val, max_val) in simulator.parameters_range.items():\n",
    "    if param_name not in top_parameters_sa:\n",
    "        print(f\"Fixing parameter {param_name} to a value within its range ({min_val}, {max_val})\")\n",
    "        midpoint_value = (max_val + min_val) / 2.0\n",
    "        updated_range[param_name] = (midpoint_value,midpoint_value)\n",
    "    else:\n",
    "        updated_range[param_name] = simulator.parameters_range[param_name]# Fix to a value\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Updated parameters range with fixed values for non-sensitive parameters:\")\n",
    "print(updated_range)simulator.parameters_range = updated_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient level calibration\n",
    "\n",
    "To refine our emulator, we need real-world observations to compare against. These observations can come from experiments reported in the literature. \n",
    "\n",
    "In this example, we'll generate synthetic \"observations\" by running the simulator at the midpoint of each parameter range, treating these as our \"ground truth\" values for calibration. Note that in a real world example one can have multiple observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:35.660353Z",
     "start_time": "2025-07-30T13:48:33.541589Z"
    }
   },
   "outputs": [],
   "source": [
    "# Calculate midpoint parameters\n",
    "midpoint_params = []\n",
    "for param_name in simulator.parameters_range:\n",
    "    # Calculate the midpoint of the parameter range\n",
    "    min_val, max_val = simulator.parameters_range[param_name]\n",
    "    midpoint_params.append((max_val + min_val) / 2.0)\n",
    "\n",
    "# Run the simulator with midpoint parameters\n",
    "midpoint_results = simulator.forward(torch.tensor(midpoint_params).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-30T13:48:35.667290Z",
     "start_time": "2025-07-30T13:48:35.657008Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create observations dictionary\n",
    "observations = {\n",
    "    name: (val.item(), max(abs(val.item()) * 0.01, 0.01)) for\n",
    "    name, val in \n",
    "    zip(simulator.output_names, midpoint_results[0])}\n",
    "observations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History Matching\n",
    "\n",
    "Once the influential parameters have been selected with sensitivity analysis, we want to find which values of those parameters are consistent with the clinical data for a specific patient. Rather than directly estimating the parameters, history matching first focuses on excluding regions of the parameter space that are not plausible.\n",
    "\n",
    "AutoEmulate has the history matching workflow where we use the simulator and a fast emulator to generate model predictions for many parameter combinations.\n",
    "\n",
    "For each simulation, \n",
    "\n",
    "- Compare the model output f(θ) to the observed data $y_{obs}$.  \n",
    "- Compute an implausibility measure for each parameter set: $I_i(\\overline{x_0}) = \\frac{|z_i - \\mathbb{E}(f_i(\\overline{x_0}))|}{\\sqrt{\\text{Var}[z_i - \\mathbb{E}(f_i(\\overline{x_0}))]}}$\n",
    "- Rule out all θ such that I(θ)>threshold (e.g., 3).\n",
    "\n",
    "Repeat this in waves:\n",
    "\n",
    "- After each wave, retrain the emulator on the non-implausible region (NROY).\n",
    "- Stop when the NROY region changes little between waves (e.g., <10% of new points are excluded).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now need to train a Gaussian Process emulator as we need uncertainty quantification for History Matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-07-30T13:48:35.663368Z"
    },
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.experimental.emulators.gaussian_process.exact import GaussianProcessExact\n",
    "\n",
    "ae_hm = AutoEmulate(\n",
    "    x, \n",
    "    y, \n",
    "    models=[GaussianProcessExact],  \n",
    ")\n",
    "\n",
    "model_hm = ae_hm.best_result().model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a HistoryMatchingWorkflow object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.experimental.calibration.history_matching import HistoryMatchingWorkflow\n",
    "\n",
    "hmw = HistoryMatchingWorkflow(\n",
    "    simulator=simulator,\n",
    "    emulator=model_hm,\n",
    "    observations=observations,\n",
    "    threshold=3.0,\n",
    "    train_x=x.float(),\n",
    "    train_y=y.float()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run waves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Save the results\n",
    "history_matching_results = hmw.run_waves(n_waves=10, n_simulations=1024, n_test_samples=8192,max_retries=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "#get last values from HM\n",
    "test_parameters, impl_scores = history_matching_results[-1]\n",
    "nory_points = hmw.get_nroy(impl_scores,test_parameters) # Implausibility < 3.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.experimental.calibration.history_matching_dashboard import HistoryMatchingDashboard\n",
    "dashboard = HistoryMatchingDashboard(\n",
    "    samples=test_parameters,\n",
    "    impl_scores=impl_scores,\n",
    "    param_names=simulator.param_names,  \n",
    "    output_names=simulator.output_names, \n",
    "    )\n",
    "dashboard.display()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "params_post_hm = hmw.generate_param_bounds(nroy_x=nory_points,param_names=simulator.param_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "params_post_hm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "simulator.parameters_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian calibration\n",
    "With the reduced and plausible parameter space from history matching, we now perform Bayesian inference to estimate the posterior distribution of parameters given patient data. We apply the following steps:\n",
    "\n",
    "- Define a prior over parameters using the NROY region from history matching.\n",
    "\n",
    "- Define a likelihood function that compares model predictions to patient data, including observation and model error.\n",
    "\n",
    "- Use a Bayesian method (MCMC) to sample from the posterior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.experimental.calibration.bayes import BayesianCalibration\n",
    "\n",
    "bc = BayesianCalibration(\n",
    "    model_hm,\n",
    "    # the parameter range here could be narrowd using history matching\n",
    "    # specifically the `hm.generate_param_bounds` method\n",
    "    simulator.parameters_range,\n",
    "    observations = {k: torch.tensor(v[0]) for k,v in observations.items()},\n",
    "    observation_noise={k: v[1] for k,v in observations.items()},\n",
    "    # if had top N sensitive params, could pass those here\n",
    "    calibration_params = top_parameters_sa\n",
    ")\n",
    "\n",
    "mcmc = bc.run_mcmc(warmup_steps=10, num_samples=10, sampler='nuts')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupyter": {
   "tags": [
    "skip-execution"
   ]
  },
  "kernelspec": {
   "display_name": "poetry-ae-casestudy",
   "language": "python",
   "name": "poetry-ae-casestudy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
