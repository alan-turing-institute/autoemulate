{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient calibration workflow using AutoEmulate\n",
    "\n",
    "## Introduction\n",
    "\n",
    "\n",
    "## The Nagavi model\n",
    "\n",
    "<!-- <b>In this workflow we demonstrate the integration of a Cardiovascular simulator, Naghavi Model from ModularCirc in an end-to-end AutoEmulate workflow.</b>  -->\n",
    "\n",
    "The Nagavi lumped parameter model is a mathematical model of the human cardiovascular system, designed to simulate the dynamics of blood flow and pressure throughout the heart and circulatory system using lumped parameter modeling. \n",
    "A **lumped parameter model** simplifies the cardiovascular system by dividing it into compartments (or \"lumps\") such as:\n",
    "\n",
    "- Heart chambers (left and right atria and ventricles)\n",
    "- Major blood vessels (aorta, vena cava, pulmonary arteries and veins)\n",
    "- Systemic and pulmonary circulations\n",
    "\n",
    "Each compartment is modeled using analogies to electrical circuits:\n",
    "\n",
    "- Pressure ↔ Voltage\n",
    "- Flow ↔ Current\n",
    "- Resistance ↔ Vascular resistance (R\\)\n",
    "- Compliance ↔ Vessel elasticity or capacitance (C\\)\n",
    "- Inertance ↔ Blood inertia (L)\n",
    "\n",
    "This approach allows simulation of the time-dependent relationships between pressure, volume, and flow rate across the entire cardiovascular system using ordinary differential equations (ODEs).\n",
    "\n",
    "The Nagavi lumped parameter model is a mathematical model of the human cardiovascular system, designed to simulate the dynamics of blood flow and pressure throughout the heart and circulatory system using lumped parameter modeling. \n",
    "A **lumped parameter model** simplifies the cardiovascular system by dividing it into compartments (or \"lumps\") such as:\n",
    "\n",
    "## Patient calibration workflow\n",
    "\n",
    "In this tutorial, we present a three-stage workflow for calibrating the Nagavi model to patient-specific clinical data using AutoEmulate. The process has the following stages:\n",
    "\n",
    "- First we perform a global sensitivity analysis, which identifies the most influential parameters affecting model outputs and reduces the dimensionality of the calibration problem. \n",
    "- Next, we apply history matching, a sequential uncertainty quantification technique that uses emulators to efficiently rule out implausible regions of the parameter space based on observed patient data. This results in a restricted, plausible region—known as the NROY (Not Ruled Out Yet) space—where parameters are consistent with the clinical measurements within acceptable uncertainty bounds. \n",
    "- Finally, we perform Bayesian inference within this NROY region to estimate the full posterior distribution of the remaining parameters, capturing the most likely values and their associated uncertainty. \n",
    "\n",
    "### Global sensitivity analysis\n",
    "\n",
    "The Nagavi model has 16 parameters which makes individual patient calibration challenging. To address this we use a emulator-based global sensitivity analysis to quantify the influence each parameter on features derived from left ventricle artery pressure. This approach reduces the parameters that will be used in model personalization from 16 to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from autoemulate.data.utils import set_random_seed\n",
    "seed = 42\n",
    "set_random_seed(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up simulator and generate data\n",
    "\n",
    "For this tutorial we use `ModularCirc` a package that providse a framework for building 0D models and simulating cardiovascular flow and mechanics. The `NaghaviSimulator` simulates pressure traces, we then choose to output summary statistics for each of the simulated traces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cardiac_simulator import NaghaviSimulator\n",
    "\n",
    "simulator = NaghaviSimulator(\n",
    "    output_variables=['lv.P'],  # We simulate the left ventricle pressure\n",
    "    n_cycles=300, \n",
    "    dt=0.001,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simulator comes with predefined input parameters ranges. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.parameters_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can sample from those to generate data to train the emulator with. By default, the `sample_inputs` method uses Latin Hypercube Sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_samples = 1024\n",
    "x = simulator.sample_inputs(N_samples,random_seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we use the simulator to generate predictions for the sampled parameters. Alternatively, for convenience, we can load already simulated data saved to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "save = True\n",
    "\n",
    "if not os.path.exists(f'simulator_results_{N_samples}.csv'):\n",
    "    # Run batch simulations with the samples generated in Cell 1\n",
    "    y, x = simulator.forward_batch(x)\n",
    "    \n",
    "    # Convert results to DataFrame for analysis\n",
    "    results_df = pd.DataFrame(y)\n",
    "    inputs_df = pd.DataFrame(x)\n",
    "    \n",
    "    if save:\n",
    "        # Save the results to a CSV file\n",
    "        results_df.to_csv(f'simulator_results_{N_samples}.csv', index=False)\n",
    "        inputs_df.to_csv(f'simulator_inputs_{N_samples}.csv', index=False)\n",
    "\n",
    "else:\n",
    "    # Read the results from the CSV file\n",
    "    results_df = pd.read_csv(f'simulator_results_{N_samples}.csv')\n",
    "    inputs_df = pd.read_csv(f'simulator_inputs_{N_samples}.csv')\n",
    "\n",
    "    y = torch.tensor(results_df.to_numpy())\n",
    "    x = torch.tensor(inputs_df.to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the output summary variables we've simulated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator.output_names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train emulator with AutoEmulate\n",
    " \n",
    "To perform sensitivity analysis efficiently, we first need to construct an emulator—a fast, surrogate model that approximates the output of the full simulator. The simulated inputs and outputs from the cell above are  used to train the emulator, in this case we choose to use a neural network trained with default hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.core.compare import AutoEmulate\n",
    "\n",
    "from autoemulate.emulators.nn.mlp import MLP\n",
    "\n",
    "ae = AutoEmulate(\n",
    "    x, \n",
    "    y, \n",
    "    models=[MLP],  \n",
    "    # use default MLP params\n",
    "    model_params={}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "ae.summarise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the best performing emulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "model = ae.best_result().model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run Sensitivity Analysis \n",
    "\n",
    "The emulator trained above can predict model outputs rapidly across the entire parameter space, allowing us to estimate global sensitivity measures like Sobol’ indices or Morris elementary effects without repeatedly calling the full simulator. This approach enables scalable and accurate sensitivity analysis, especially in high-dimensional or computationally intensive settings.\n",
    "\n",
    "Here we use AutoEmulate to perform sensitivity analysis and plot the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.core.sensitivity_analysis import SensitivityAnalysis\n",
    "\n",
    "# Define the problem dictionary for Sobol sensitivity analysis\n",
    "problem = {\n",
    "    'num_vars': simulator.in_dim,\n",
    "    'names': simulator.param_names,\n",
    "    'bounds': simulator.param_bounds\n",
    "}\n",
    "\n",
    "si = SensitivityAnalysis(model, problem=problem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "si_df = si.run(method='sobol')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "si.plot_sobol(si_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "si.plot_sa_heatmap(si_df, index='ST', cmap='coolwarm', normalize=True, figsize=(10, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can select the top 3 parameters that have the biggest influcence on the pressure wave summary statistics extracted from the Nagavi Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "n_parameters = 3\n",
    "top_parameters_sa = si.top_n_sobol_params(si_df, top_n=n_parameters)\n",
    "top_parameters_sa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The parameters that are found to be less influential are fixed to a mid point value within its range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "updated_range = {}\n",
    "for param_name, (min_val, max_val) in simulator.parameters_range.items():\n",
    "    if param_name not in top_parameters_sa:\n",
    "        midpoint_value = (max_val + min_val) / 2.0\n",
    "        updated_range[param_name] = (midpoint_value, midpoint_value)\n",
    "        print(f\"Fixing parameter {param_name} to a midpoint value {midpoint_value} within its range ({min_val}, {max_val})\")\n",
    "    else:\n",
    "        updated_range[param_name] = simulator.parameters_range[param_name]# Fix to a value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "print(\"Updated parameters range with fixed values for non-sensitive parameters:\")\n",
    "print(updated_range)\n",
    "simulator.parameters_range = updated_range"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Patient level calibration\n",
    "\n",
    "To refine our emulator, we need real-world observations to compare against. These observations can come from experiments reported in the literature. \n",
    "\n",
    "In this example, we'll generate synthetic \"observations\" by running the simulator at the midpoint of each parameter range, treating these as our \"ground truth\" values for calibration. Note that in a real world example one can have multiple observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Calculate midpoint parameters\n",
    "midpoint_params_patient = []\n",
    "patient_true_values = {}\n",
    "for param_name in simulator.parameters_range:\n",
    "    # Calculate the midpoint of the parameter range\n",
    "    min_val, max_val = simulator.parameters_range[param_name]\n",
    "    midpoint_params_patient.append((max_val + min_val) / 2.0)\n",
    "    patient_true_values[param_name] = midpoint_params_patient[-1]\n",
    "\n",
    "# Run the simulator with midpoint parameters\n",
    "midpoint_results = simulator.forward(torch.tensor(midpoint_params_patient).reshape(1, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Create observations dictionary\n",
    "observations = {\n",
    "    name: (val.item(), max(abs(val.item()) * 0.05, 0.05)) for\n",
    "    name, val in \n",
    "    zip(simulator.output_names, midpoint_results[0])}\n",
    "observations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History Matching\n",
    "\n",
    "Once the influential parameters have been selected with sensitivity analysis, we want to find which values of those parameters are consistent with the clinical data for a specific patient such as the observations generated above. Rather than directly estimating the parameters, history matching first focuses on excluding regions of the parameter space that are not plausible. \n",
    "\n",
    "Given emulator predictions for a number of possible parameter sets $f(θ)$ and observed data $y_{obs}$, history matching:\n",
    "- Computes an implausibility measure for each parameter set: $I(\\theta) = \\frac{|y_{obs} - \\mathbb{E}[f(\\theta)]|}{\\sqrt{\\text{Var}[f(\\theta)]}}$\n",
    "- Rule out all $θ$ such that $I(θ)>$ threshold (e.g., 3).\n",
    "\n",
    "The denominator in the implausability calculation can optionally include uncertainty in the observations or a model discrepancy term."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since history matching requires predictive variance, below we train a Gaussian Process emulator. The emulator is trained on to predict the outputs given only the most sensitive parameters as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "x = simulator.sample_inputs(500,random_seed=seed)\n",
    "y, x = simulator.forward_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.emulators.gaussian_process.kernel import matern_3_2_kernel\n",
    "\n",
    " # only train sensitive parameters\n",
    "sa_parameter_idx = [\n",
    "    simulator.get_parameter_idx(param) for param in top_parameters_sa\n",
    "]\n",
    "\n",
    "ae_hm = AutoEmulate(\n",
    "    # only use sensitive parameters as inputs to emulator\n",
    "    x[:, sa_parameter_idx], \n",
    "    y, \n",
    "    models=[\"GaussianProcess\"],  \n",
    "    # use Matern 3/2 kernel with default params\n",
    "    model_params = {\n",
    "        'covar_module': matern_3_2_kernel,\n",
    "        'standardize_x': True,\n",
    "        'standardize_y': True\n",
    "        \n",
    "    }\n",
    ")\n",
    "\n",
    "res = ae_hm.best_result()\n",
    "gp_matern = res.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could now use the emulator to make predictions and evaluate those predictions against observations as described above.\n",
    "\n",
    "However, we often want to run history matching iteratively and make use of the simulator to continually improve the emulator and the calibration results. \n",
    "\n",
    "To this end, AutoEmulate implements the `HistoryMatchingWorkflow`, which can run multiple \"waves\" of history matching. In each wave:\n",
    "- new parameters are sampled from the not ruled out yet (NROY) space and evaluated on their plausability using an emulator\n",
    "- new simulations are run for a subset of those parameters\n",
    "- the emulator is retrained with the newly simulated data\n",
    "\n",
    "The `HistoryMatchingWorkflow` object takes in the simulator, the trained emulator and observations. Since the emulator was trained on a subset of the simulation parameters, we need to specify which parameters those are. `HistoryMatchingWorkflow` can also optionally be passed the data the emulator was trained on to reuse when retraining the emulator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.calibration.history_matching import HistoryMatchingWorkflow\n",
    "\n",
    "hmw = HistoryMatchingWorkflow(\n",
    "    simulator=simulator,\n",
    "    result=ae_hm.best_result(),\n",
    "    observations=observations,\n",
    "    threshold=3.0,\n",
    "    train_x=x.float(),\n",
    "    train_y=y.float(),\n",
    "    # specify subset of simulator parameters to calibrate\n",
    "    # these are the input parameters the emulator was trained on\n",
    "    calibration_params=top_parameters_sa,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The workflow is called with the `run_waves` method. The user can specify how many waves to run but when the NROY region changes little between waves (e.g., <10% of new points are excluded) then the workflow is stopped even if not all waves have been completed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "n_waves=5\n",
    "\n",
    "history_matching_results = hmw.run_waves(\n",
    "    n_waves=n_waves, \n",
    "    # the number of simulations to run each wave\n",
    "    n_simulations=100, \n",
    "    # number of parameter samples to draw from which to select NROY samples to simulate\n",
    "    n_test_samples=1000,\n",
    "    # how many times to resample if can't generate n_simulations NROY samples\n",
    "    max_retries=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below figure shows the implausibility scores for each parameter combination, allowing us to visualize which regions of the parameter space are plausible (i.e., not ruled out yet) based on the observed data in a given wave. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# include the \"true\" value for reference\n",
    "ref_val = [float(patient_true_values[param]) for param in top_parameters_sa]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmw.plot_wave(wave=1, ref_val=ref_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmw.plot_wave(wave=1, ref_val=ref_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we confirm that the ranges for the parameters of interest have reduced compared to the simulator default ranges. This is especially true for the most sensitive parameter `lv.k_pas`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "# Get the last wave results\n",
    "test_parameters, impl_scores = hmw.wave_results[-1]\n",
    "nroy_points = hmw.get_nroy(impl_scores,test_parameters) # Implausibility < 3.0\n",
    "\n",
    "# Get exact min/max bounds for the parameters from the NROY points\n",
    "params_post_hm = hmw.generate_param_bounds(\n",
    "    nroy_x=nroy_points,\n",
    "    param_names=simulator.param_names, \n",
    "    buffer_ratio=0.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "for param_name, bounds in params_post_hm.items():\n",
    "    if param_name in top_parameters_sa:\n",
    "        print(f\"Param name: {param_name}\")\n",
    "        a, b = simulator.parameters_range[param_name]\n",
    "        print (f\"Pre HM parameter bounds: {(float(a),float(b))}\")\n",
    "        a, b = bounds\n",
    "        print (f\"Post HM parameter bounds: {(round(a, 3), round(b, 3))}\")\n",
    "        print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bayesian calibration\n",
    "With the reduced parameter space from history matching, we now perform Bayesian inference to estimate the posterior distribution of parameters given the observed patient data. We apply the following steps:\n",
    "\n",
    "- Define a prior over parameters using the NROY region from history matching.\n",
    "\n",
    "- Define a likelihood function that compares model predictions to patient data, including observation and model error.\n",
    "\n",
    "- Use a Bayesian method (MCMC) to sample from the posterior.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from autoemulate.calibration.bayes import BayesianCalibration\n",
    "\n",
    "model_post_hm = hmw.emulator  # Use the emulator from history matching\n",
    "\n",
    "bc = BayesianCalibration(\n",
    "    emulator=model_post_hm,\n",
    "    parameter_range={k:v for k,v in params_post_hm.items() if k in top_parameters_sa},\n",
    "    observations = {k: torch.tensor(v[0]) for k,v in observations.items()},\n",
    "    # take account of the emulator uncertainty\n",
    "    model_uncertainty=True,\n",
    "    # specify observation noise as variance\n",
    "    observation_noise={k: v[1]**2 for k,v in observations.items()}\n",
    ")\n",
    "\n",
    "mcmc = bc.run_mcmc(warmup_steps=250, num_samples=1000, sampler='nuts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "mcmc.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check if the posterior samples are consistent with the true values of the parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "idata = bc.to_arviz(mcmc)\n",
    "\n",
    "az.plot_posterior(\n",
    "    idata, \n",
    "    var_names=top_parameters_sa, \n",
    "    kind='hist', \n",
    "    figsize=(10, 6), \n",
    "    ref_val=ref_val\n",
    ")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "output_name = f\"results_waves_{n_waves}_sa_params_{n_parameters}.html\"\n",
    "\n",
    "!jupyter nbconvert --to html ModularCirc.ipynb  --output {output_name}"
   ]
  }
 ],
 "metadata": {
  "jupyter": {
   "tags": [
    "skip-execution"
   ]
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
