{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Minimising computation time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`AutoEmulate` can be slow if the input data has many observations (rows) or many output variables. By default, `AutoEmulate` cross-validates each model, so we're computing 5 fits per models. The computation time will be relatively short for datasets up to a few thousands of datapoints, but some models (e.g. Gaussian Processes) don't scale well, so computation time might quickly become an issue. \n",
    "\n",
    "In this tutorial we walk through four strategies to speed up `AutoEmulate`:\n",
    "\n",
    "1) parallelise model fits using `n_jobs` \n",
    "2) restrict the range of models using the `models` argument \n",
    "3) run fewer cross validation folds using `cross_validator` \n",
    "4) for hyperparameter search:\n",
    "    - all of the above\n",
    "    - run fewer iterations using `param_search_iters`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from autoemulate.compare import AutoEmulate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_samples=500, n_features=10, n_targets=5)\n",
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And see how long `AutoEmulate` takes to run (without hyperparameter search)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "em = AutoEmulate()\n",
    "em.setup(X, y)\n",
    "em.compare()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) parallise model fits using `n_jobs`\n",
    "The n_jobs parameter allows you to specify the number of CPU cores to use for parallel processing. Setting n_jobs = -1  uses all available cores, speeding up computations when working with large datasets.\n",
    "\n",
    "Note: Maxing out all available cores might not always lead to faster computation times. Due to overhead from parallelization, memory bandwidth limitations, and potential load imbalances, using more cores can sometimes result in diminishing returns or even slower performance.\n",
    "\n",
    "Here we accomplish a speed-up by setting n_jobs to 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "em = AutoEmulate()\n",
    "em.setup(X, y, n_jobs=5, print_setup=False)\n",
    "em.compare()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) restrict the range of models\n",
    "\n",
    "Another approach is to limit the range of models by selecting a subset of relevant types based on your domain and problem expertise. This selection process typically considers factors such as the nature of the problem, data characteristics or the need for interpretability. By narrowing down the types of models, you can reduce the computational burden and focus on the most promising architectures for your specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = AutoEmulate()\n",
    "em.setup(X, y, print_setup=False)\n",
    "\n",
    "# let's see all models, which we can refer to by short or full name\n",
    "em.model_registry.get_model_names()\n",
    "\n",
    "# setup with fewer models\n",
    "start = time.time()\n",
    "\n",
    "em.setup(X, y, models=[\"sop\", \"rbf\", \"gb\"], print_setup=False)\n",
    "em.compare()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3) reduce the number of folds in cross validation using `cross_validator` "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With larger datasets, you might initially want to set the number of folds for the cross validation to 3 instead of 5 (the default), so that there are fewer models to fit. `AutoEmulate` takes a `cross_validator` argument, which takes an scklearn cross validator or [splitter](https://scikit-learn.org/stable/api/sklearn.model_selection.html). Let's use kfold with 3 splits, which saves 2 model fits per model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "em = AutoEmulate()\n",
    "em.setup(X, y, cross_validator=KFold(n_splits=3), print_setup=False)\n",
    "em.compare()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) modify hyperparameter search\n",
    "\n",
    "If we want to use hyperparameter search, we suddenly have to fit many more models. For each model, we might have 20 different parameter combinations, and because we cross validate each combination, we are running 20 * 5 = 100 model fits per model. It's therefore recommended to focus on a few models of interest when using hyperparameter search.\n",
    "\n",
    "To get a ballpark figure for how long hyperparameter search might take, we can run `AutoEmulate` without hyperparameter search, and then multiply the time taken by the number of parameter combinations we want to try."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "em = AutoEmulate()\n",
    "em.setup(X, y, print_setup=False)\n",
    "em.compare()\n",
    "\n",
    "end = time.time()\n",
    "run_time = end - start\n",
    "print(f\"Time taken: {run_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default number parameter combinations to search over (see`param_search_iters`) is 20, so we can expect hyperparameter search to take `20 * run_time` seconds. Although this can be sped up by running in parallel or running fewer cross-validation folds, we are usually interested only in some emulator models anyway, which will speed up computation time. To figure out which models to optimise, let's inspect the cv results from the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em.summarise_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we might like to see whether the Support Vector Machines model could do better with better hyperparameters. To minimise computation time, we only take those this one model, and run 50 iterations (instead of the default 20), we run them in parallel using 5 jobs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "em_svm = AutoEmulate()\n",
    "em_svm.setup(X, y, models=[\"svm\"], param_search=True, param_search_iters=50, \n",
    "         n_jobs=5, print_setup=False)\n",
    "em_svm.compare()\n",
    "\n",
    "end = time.time()\n",
    "print(f\"Time taken: {end - start} seconds\")\n",
    "\n",
    "em_svm.summarise_cv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And indeed, the SVM model does perform better with better hyperparameters! Let's have a look at them. SVM is a pipeline, so we first extract the 'model' step, and then get the parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = em_svm.get_model(name=\"svm\")\n",
    "svm.named_steps['model'].get_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
