{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Converting Emulators to Pyomo Expressions\n",
    "\n",
    "This tutorial's purpose is to walk you through the process of converting your `AutoEmulate` models to Pyomo algebraic expressions for easy optimization workflows. Currently only `PolynomialRegression` and `MLP` are supported for this conversion.\n",
    "\n",
    "We'll demonstrate the following steps:\n",
    "1. Training a Neural Network (MLP) on a simple toy function using `AutoEmulate`\n",
    "2. Exporting the trained network into algebraic expressions compatible with Pyomo\n",
    "3. Validating the Pyomo expressions against PyTorch predictions\n",
    "\n",
    "### Prerequisites\n",
    "\n",
    "* `autoemulate`\n",
    "* `pyomo`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports for the notebook\n",
    "import warnings\n",
    "import numpy as np\n",
    "import torch\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy simulation\n",
    "\n",
    "Before we build an emulator with AutoEmulate, we need to get a set of input/output pairs from our simulation to use as training data.\n",
    "\n",
    "Below is a simple toy simulation that computes the product of two inputs: `y = x1 * x2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data: y = x1 * x2\n",
    "n_samples = 1000\n",
    "x1 = np.random.uniform(-100, 100, size=n_samples)\n",
    "x2 = np.random.uniform(-100, 100, size=n_samples)\n",
    "\n",
    "def F(x1, x2):\n",
    "    return x1 * x2\n",
    "\n",
    "x = np.column_stack((x1, x2))\n",
    "y = F(x1, x2)\n",
    "\n",
    "# Convert to tensors for AutoEmulate\n",
    "x = torch.tensor(x, dtype=torch.float32)\n",
    "y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "As you can see, our simulator inputs (`x`) and outputs (`y`) are PyTorch tensors. PyTorch tensors are a common data structure used in machine learning, and `AutoEmulate` is built to work with them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Emulator\n",
    "\n",
    "For this tutorial, we'll focus on training an MLP (Multi-Layer Perceptron) neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate import AutoEmulate\n",
    "\n",
    "# Initialize AutoEmulate with MLP model only\n",
    "ae = AutoEmulate(x, y, log_level=\"info\", models=['MLP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have run `AutoEmulate`, let's look at the summary for the emulator performance (r-squared and RMSE) on both the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.summarise()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing an Emulator\n",
    "\n",
    "From this list, we can choose an emulator based on the index from the summary dataframe, or quickly get the best performing one using the `best_result` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best = ae.best_result()\n",
    "print(\"Model with id: \", best.id, \" performed best: \", best.model_name)\n",
    "\n",
    "# best = ae.get_models('MLP')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the configuration of the best model. These are the values of the model's hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(best.params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting to Pyomo\n",
    "\n",
    "Now that we have a trained emulator, we can convert it to Pyomo algebraic expressions. This allows us to use the emulator in optimization problems with mathematical programming solvers.\n",
    "\n",
    "First, we need to set up a Pyomo model and define decision variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyomo.environ as pyo\n",
    "\n",
    "# Create a Pyomo concrete model\n",
    "pyo_model = pyo.ConcreteModel()\n",
    "\n",
    "# Pick a test point for initialization\n",
    "x_init = x[0]\n",
    "\n",
    "# Define decision variables\n",
    "# We use the real domain since our training data spans [-100, 100]\n",
    "pyo_model.x1 = pyo.Var(domain=pyo.Reals)\n",
    "pyo_model.x2 = pyo.Var(domain=pyo.Reals)\n",
    "\n",
    "# Initialize to a known point\n",
    "pyo_model.x1.set_value(x_init[0].item())\n",
    "pyo_model.x2.set_value(x_init[1].item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Neural Network to Pyomo\n",
    "\n",
    "This is the core integration step. The `pyomofy` function converts the neural network's weights, biases, and activation functions into explicit algebraic expressions.\n",
    "\n",
    "It automatically handles:\n",
    "\n",
    "* **Input Standardization:** Scaling Pyomo variables to the statistical distribution the network expects\n",
    "* **Forward Pass:** Generating constraints for every layer\n",
    "* **Output Inverse Scaling:** Converting the network output back to real-world units\n",
    "* **ReLU Approximation:** If `nn.ReLU` was used during training, it's automatically approximated with Softplus (controlled by the `relu_beta` parameter). Increase `relu_beta` value if results mismatch significantly, or use a smooth activation function like `SiLU` during training:\n",
    "```\n",
    "from torch import nn\n",
    "\n",
    "# Train with smooth activation for better Pyomo conversion\n",
    "ae = AutoEmulate(\n",
    "    x, y, \n",
    "    models=['MLP'],\n",
    "    model_params={'activation_cls': nn.SiLU}  # Use SiLU instead of ReLU\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.convert.pyomo import pyomofy\n",
    "\n",
    "# Convert the best model to Pyomo expressions\n",
    "# Pass the Result object (or TransformedEmulator) and the list of Pyomo variables\n",
    "# Returns a list of expressions (one per output dimension)\n",
    "emulator_expressions = pyomofy(best, [pyo_model.x1, pyo_model.x2], relu_beta=100)\n",
    "\n",
    "# Since our output is 1D (the product), we take the first expression\n",
    "emulator_expr = emulator_expressions[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verify Numerical Equivalence\n",
    "\n",
    "Before using the Pyomo expressions in optimization, we **must** verify that they yield the same values as the PyTorch model. This validation ensures the conversion was successful and the algebraic expressions accurately represent the neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Evaluate Pyomo expression at the initialization point\n",
    "pyomo_val = pyo.value(emulator_expr)\n",
    "\n",
    "# 2. Evaluate PyTorch model at the same point\n",
    "torch_input = x[0].reshape(1, -1)\n",
    "torch_val = best.model.predict(torch_input).item()\n",
    "\n",
    "# Print comparison\n",
    "print(f\"Input point:        x1={x_init[0]:.4f}, x2={x_init[1]:.4f}\")\n",
    "print(f\"PyTorch prediction: {torch_val:.12f}\")\n",
    "print(f\"Pyomo prediction:   {pyomo_val:.12f}\")\n",
    "print(f\"\\nPyomo vs PyTorch:   {abs(pyomo_val - torch_val):.12f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using the Pyomo Expression\n",
    "\n",
    "Now that we've validated the conversion, the Pyomo expression can be used in optimization problems. Here's a simple example of how you might set up an objective function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Define an objective to maximize the emulator output\n",
    "pyo_model.obj = pyo.Objective(expr=emulator_expr, sense=pyo.maximize)\n",
    "\n",
    "# You could also use as constraints, for example:\n",
    "# pyo_model.constraint1 = pyo.Constraint(expr=emulator_expr >= 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoemulate (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
