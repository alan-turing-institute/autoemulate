{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# probabilistic programming\n",
    "import pyro \n",
    "\n",
    "# MCMC plotting\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from getdist.arviz_wrapper import arviz_to_mcsamples\n",
    "from getdist import plots\n",
    "\n",
    "# autoemulate imports\n",
    "from autoemulate.simulations.epidemic import Epidemic\n",
    "from autoemulate.core.compare import AutoEmulate\n",
    "from autoemulate.calibration.bayes import BayesianCalibration\n",
    "from autoemulate.emulators import GaussianProcessRBF\n",
    "\n",
    "# suppress warnings in notebook for readability\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "# random seed for reproducibility\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.data.utils import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "pyro.set_rng_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidence computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulate data\n",
    "\n",
    "In this example, we'll use the `Epidemic` simulator, which returns the peak infection rate given two input parameters, `beta`(the transimission rate per day) and `gamma` (the recovery rate per day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Epidemic(log_level=\"error\")\n",
    "x = simulator.sample_inputs(1000)\n",
    "y, _ = simulator.forward_batch(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the simulated data. The peak infection rate is higher when the transmission rate increases and the recovery rate decreases and the two parameters are correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_rate = x[:, 0]\n",
    "recovery_rate = x[:, 1]\n",
    "\n",
    "plt.scatter(transmission_rate, recovery_rate, c=y, cmap='viridis')\n",
    "plt.xlabel('Transmission rate (beta)')\n",
    "plt.ylabel('Recovery rate (gamma)')\n",
    "plt.colorbar(label=\"Peak infection rate\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we pick the initial parameter values and simulate the output. We then add noise to generate 100 \"observations\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_beta = 0.3\n",
    "true_gamma = 0.15 \n",
    "\n",
    "# simulator expects inputs of shape [1, number of inputs]\n",
    "params = torch.tensor([true_beta, true_gamma]).view(1, -1)\n",
    "true_infection_rate = simulator.forward(params)\n",
    "\n",
    "n_obs = 100\n",
    "stdev = 0.05\n",
    "noise = torch.normal(mean=0, std=stdev, size=(n_obs,))\n",
    "observed_infection_rates = true_infection_rate[0] + noise\n",
    "\n",
    "observations = {\"infection_rate\": observed_infection_rates}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these observations to infer which input parameters were most likely to have produced them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calibrate with simulator\n",
    "\n",
    "In this example, we have a fast simulator with only two input parameters, so we can use the simulator. The below code shows how to do this directly with Pyro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC\n",
    "from pyro.infer.mcmc import RandomWalkKernel\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str((Path.cwd() / \"docs\" / \"tutorials\" / \"tasks\").resolve()))\n",
    "\n",
    "from model import model\n",
    "\n",
    "# run Bayesian inference with MCMC\n",
    "\n",
    "\n",
    "kernel = RandomWalkKernel(model, init_step_size=2.5)\n",
    "mcmc_sim = MCMC(\n",
    "    kernel,\n",
    "    warmup_steps=500,\n",
    "    num_samples=5000,\n",
    "    num_chains=10\n",
    ")\n",
    "mcmc_sim.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the posterior samples of the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_samples = mcmc_sim.get_samples()\n",
    "    \n",
    "plt.scatter(sim_samples['beta'], sim_samples['gamma'], alpha=0.5)\n",
    "plt.xlabel('Transmission rate (beta)')\n",
    "plt.ylabel('Recovery rate (gamma)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute Evidence using AutoEmulate\n",
    "\n",
    "AutoEmulate provides a simplified interface for computing Bayesian evidence from MCMC samples using the Harmonic method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.calibration.evidence import EvidenceComputation\n",
    "\n",
    "# Create evidence computation object\n",
    "ec = EvidenceComputation(mcmc_sim, model, temperature=0.8, log_level=\"info\")\n",
    "\n",
    "# Compute the evidence\n",
    "results = ec.compute_evidence(epochs=30, verbose=True)\n",
    "\n",
    "# Display results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(f\"Evidence Computation Results\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Log Evidence:          {results['ln_evidence']:.4f}\")\n",
    "print(f\"Log Inverse Evidence:  {results['ln_inv_evidence']:.4f}\")\n",
    "print(f\"Error bounds:          [{results['error_lower']:.4f}, {results['error_upper']:.4f}]\")\n",
    "print(f\"{'='*60}\")\n",
    "print(f\"Number of chains:      {results['num_chains']}\")\n",
    "print(f\"Samples per chain:     {results['num_samples_per_chain']}\")\n",
    "print(f\"Number of parameters:  {results['num_parameters']}\")\n",
    "print(f\"{'='*60}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the Results\n",
    "\n",
    "The `compute_evidence()` method returns a dictionary with the following key information:\n",
    "\n",
    "- **`ln_evidence`**: The natural logarithm of the evidence (log marginal likelihood). This is the primary quantity used for model comparison via Bayes factors.\n",
    "- **`ln_inv_evidence`**: The log inverse evidence (as computed by Harmonic). Note: `ln_evidence = -ln_inv_evidence`.\n",
    "- **`error_lower`, `error_upper`**: Asymmetric error bounds on the log inverse evidence estimate. Tight errors (< 0.1) indicate reliable estimation.\n",
    "\n",
    "**Using Evidence for Model Comparison:**\n",
    "\n",
    "To compare two models, compute the Bayes factor:\n",
    "```python\n",
    "BF = exp(ln_evidence_model1 - ln_evidence_model2)\n",
    "```\n",
    "\n",
    "- BF > 10: Strong evidence for model 1\n",
    "- BF > 3: Moderate evidence for model 1  \n",
    "- BF â‰ˆ 1: No preference between models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Access internal Harmonic objects for advanced analysis\n",
    "chains = ec.get_chains()\n",
    "flow_model = ec.get_flow_model()\n",
    "evidence_obj = ec.get_evidence_object()\n",
    "\n",
    "print(f\"Chains object: {chains}\")\n",
    "print(f\"Flow model: {flow_model}\")\n",
    "print(f\"Evidence estimator: {evidence_obj}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Advanced: Using the Low-Level API (Optional)\n",
    "\n",
    "The simplified interface above replaces approximately 60 lines of manual code. For advanced users who need more control, the underlying functions are still available:\n",
    "\n",
    "### Manual Log Probability Extraction\n",
    "\n",
    "```python\n",
    "from autoemulate.calibration.bayes import extract_log_probabilities\n",
    "\n",
    "# Manually extract log probabilities\n",
    "samples, log_probs = extract_log_probabilities(mcmc_sim, model)\n",
    "print(f\"Samples shape: {samples.shape}\")  # (num_chains, num_samples_per_chain, ndim)\n",
    "print(f\"Log probs shape: {log_probs.shape}\")  # (num_chains, num_samples_per_chain)\n",
    "```\n",
    "\n",
    "### Direct Harmonic API Usage\n",
    "\n",
    "```python\n",
    "import harmonic as hm\n",
    "\n",
    "# Create Harmonic Chains\n",
    "chains = hm.Chains(samples.shape[2])\n",
    "chains.add_chains_3d(samples, log_probs)\n",
    "\n",
    "# Split and train flow model\n",
    "chains_train, chains_infer = hm.utils.split_data(chains, training_proportion=0.5)\n",
    "flow = hm.model.RQSplineModel(samples.shape[2], standardize=True, temperature=0.8)\n",
    "flow.fit(chains_train.samples, epochs=30, verbose=True)\n",
    "\n",
    "# Compute evidence\n",
    "ev = hm.Evidence(chains_infer.nchains, flow)\n",
    "ev.add_chains(chains_infer)\n",
    "ln_inv_evidence = ev.ln_evidence_inv\n",
    "errors = ev.compute_ln_inv_evidence_errors()\n",
    "```\n",
    "\n",
    "However, we recommend using the `EvidenceComputation` class for most use cases as it handles error checking, logging, and provides a cleaner interface."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newalan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
