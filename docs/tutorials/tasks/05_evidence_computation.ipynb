{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# probabilistic programming\n",
    "import pyro \n",
    "\n",
    "# MCMC plotting\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from getdist.arviz_wrapper import arviz_to_mcsamples\n",
    "from getdist import plots\n",
    "\n",
    "# autoemulate imports\n",
    "from autoemulate.simulations.epidemic import Epidemic\n",
    "from autoemulate.core.compare import AutoEmulate\n",
    "from autoemulate.calibration.bayes import BayesianCalibration\n",
    "from autoemulate.emulators import GaussianProcessRBF\n",
    "\n",
    "# suppress warnings in notebook for readability\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "# random seed for reproducibility\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.data.utils import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "pyro.set_rng_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evidence computation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulate data\n",
    "\n",
    "In this example, we'll use the `Epidemic` simulator, which returns the peak infection rate given two input parameters, `beta`(the transimission rate per day) and `gamma` (the recovery rate per day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Epidemic(log_level=\"error\")\n",
    "x = simulator.sample_inputs(1000)\n",
    "y, _ = simulator.forward_batch(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the simulated data. The peak infection rate is higher when the transmission rate increases and the recovery rate decreases and the two parameters are correlated with each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_rate = x[:, 0]\n",
    "recovery_rate = x[:, 1]\n",
    "\n",
    "plt.scatter(transmission_rate, recovery_rate, c=y, cmap='viridis')\n",
    "plt.xlabel('Transmission rate (beta)')\n",
    "plt.ylabel('Recovery rate (gamma)')\n",
    "plt.colorbar(label=\"Peak infection rate\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we pick the initial parameter values and simulate the output. We then add noise to generate 100 \"observations\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_beta = 0.3\n",
    "true_gamma = 0.15 \n",
    "\n",
    "# simulator expects inputs of shape [1, number of inputs]\n",
    "params = torch.tensor([true_beta, true_gamma]).view(1, -1)\n",
    "true_infection_rate = simulator.forward(params)\n",
    "\n",
    "n_obs = 100\n",
    "stdev = 0.05\n",
    "noise = torch.normal(mean=0, std=stdev, size=(n_obs,))\n",
    "observed_infection_rates = true_infection_rate[0] + noise\n",
    "\n",
    "observations = {\"infection_rate\": observed_infection_rates}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now use these observations to infer which input parameters were most likely to have produced them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calibrate with simulator\n",
    "\n",
    "In this example, we have a fast simulator with only two input parameters, so we can use the simulator. The below code shows how to do this directly with Pyro. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.distributions as dist\n",
    "from pyro.infer import MCMC\n",
    "from pyro.infer.mcmc import RandomWalkKernel\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "sys.path.insert(0, str((Path.cwd() / \"docs\" / \"tutorials\" / \"tasks\").resolve()))\n",
    "\n",
    "from model import model\n",
    "\n",
    "# run Bayesian inference with MCMC\n",
    "\n",
    "\n",
    "kernel = RandomWalkKernel(model, init_step_size=2.5)\n",
    "mcmc_sim = MCMC(\n",
    "    kernel,\n",
    "    warmup_steps=500,\n",
    "    num_samples=5000,\n",
    "    num_chains=10\n",
    ")\n",
    "mcmc_sim.run()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we plot the posterior samples of the input parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_samples = mcmc_sim.get_samples()\n",
    "    \n",
    "plt.scatter(sim_samples['beta'], sim_samples['gamma'], alpha=0.5)\n",
    "plt.xlabel('Transmission rate (beta)')\n",
    "plt.ylabel('Recovery rate (gamma)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Compute the evidence based on the harmonics\n",
    "\n",
    "Compute the log probability for each posterior sample produced by MCMC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyro.poutine as poutine\n",
    "\n",
    "\n",
    "samples = mcmc_sim.get_samples(group_by_chain=True)\n",
    "num_chains = samples[\"beta\"].shape[0]\n",
    "num_samples_per_chain = samples[\"beta\"].shape[1]\n",
    "\n",
    "\n",
    "log_probs_list = []\n",
    "\n",
    "for chain_idx in range(num_chains):\n",
    "    chain_log_probs = []\n",
    "    for sample_idx in range(num_samples_per_chain):\n",
    "        sample_params = {k: v[chain_idx, sample_idx] for k, v in samples.items()}\n",
    "        \n",
    "        conditioned_model = pyro.condition(model, data=sample_params)\n",
    "        \n",
    "        trace = poutine.trace(conditioned_model).get_trace()\n",
    "        log_prob = trace.log_prob_sum()\n",
    "        \n",
    "        chain_log_probs.append(log_prob.item())\n",
    "    log_probs_list.append(chain_log_probs)\n",
    "\n",
    "# sim_samples: (num_chains, num_samples_per_chain, ndim)\n",
    "sim_samples = torch.stack([samples[k] for k in samples.keys()], dim=-1)\n",
    "\n",
    "# log_probs_tensor: (num_chains, num_samples_per_chain)\n",
    "log_probs_tensor = torch.tensor(log_probs_list)\n",
    "\n",
    "print(f\"sim_samples shape: {sim_samples.shape}\")\n",
    "print(f\"log_probs_tensor shape: {log_probs_tensor.shape}\")\n",
    "print(f\"num_chains: {num_chains}, num_samples_per_chain: {num_samples_per_chain}\")\n",
    "\n",
    "samples_flat = mcmc_sim.get_samples()\n",
    "plt.scatter(samples_flat['beta'], samples_flat['gamma'], alpha=0.5)\n",
    "plt.xlabel('Transmission rate (beta)')\n",
    "plt.ylabel('Recovery rate (gamma)')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install harmonic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Harmonic Chains, split train/infer sets, fit a flow model (e.g. RQSpline), and compute the (log) inverse evidence and its error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importance-sampling from the prior, then fit harmonic flow to posterior samples\n",
    "import harmonic as hm\n",
    "\n",
    "chains = hm.Chains(sim_samples.shape[2])\n",
    "chains.add_chains_3d(sim_samples, log_probs_tensor)\n",
    "\n",
    "\n",
    "# Split into train / inference for flow training\n",
    "chains_train, chains_infer = hm.utils.split_data(chains, training_proportion=0.5)\n",
    "\n",
    "# Train a flow model (RQSpline) on training posterior samples\n",
    "temperature = 0.8\n",
    "model = hm.model.RQSplineModel(sim_samples.shape[2], standardize=True, temperature=temperature)\n",
    "model.fit(chains_train.samples, epochs=30, verbose=True)\n",
    "\n",
    "# Instantiate harmonic's evidence class\n",
    "ev = hm.Evidence(chains_infer.nchains, model)\n",
    "\n",
    "# Pass the evidence class the inference chains and compute the evidence!\n",
    "ev.add_chains(chains_infer)\n",
    "ln_inv_evidence = ev.ln_evidence_inv\n",
    "err_ln_inv_evidence = ev.compute_ln_inv_evidence_errors()\n",
    "print(f'Log Inverse Evidence: {ln_inv_evidence} Â± {err_ln_inv_evidence}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "newalan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
