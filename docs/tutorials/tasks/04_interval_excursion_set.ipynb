{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# probabilistic programming\n",
    "import pyro \n",
    "\n",
    "# MCMC plotting\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from getdist import plots\n",
    "\n",
    "# autoemulate imports\n",
    "from autoemulate.calibration.interval_excursion_set import IntervalExcursionSetCalibration\n",
    "from autoemulate.calibration.history_matching import HistoryMatchingWorkflow\n",
    "from autoemulate.core.compare import AutoEmulate\n",
    "from autoemulate.data.utils import set_random_seed\n",
    "from autoemulate.simulations.projectile import Projectile\n",
    "from autoemulate.emulators.gaussian_process.exact import GaussianProcessRBF\n",
    "\n",
    "# suppress warnings in notebook for readability\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "# random seed for reproducibility\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projectile simulation: run simulator and fit emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_random_seed(random_seed)\n",
    "pyro.set_rng_seed(random_seed)\n",
    "\n",
    "simulator = Projectile(log_level=\"error\")\n",
    "x = simulator.sample_inputs(1000)\n",
    "y, _ = simulator.forward_batch(x)\n",
    "\n",
    "c = x[:, 0]\n",
    "v0 = x[:, 1]\n",
    "\n",
    "plt.scatter(c, v0, c=y[:, 0], cmap='viridis')\n",
    "plt.xlabel('Drag coefficient')\n",
    "plt.ylabel('Initial velocity (m/s)')\n",
    "plt.colorbar(label=\"Distance (m)\")\n",
    "plt.show()\n",
    "\n",
    "ae = AutoEmulate(\n",
    "    x, \n",
    "    y, \n",
    "    models=[GaussianProcessRBF],\n",
    "    model_params={},\n",
    "    log_level=\"error\", \n",
    ")\n",
    "\n",
    "gp = ae.best_result().model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set-up: identify an interval excursion set for $f(x)$\n",
    "\n",
    "The aim for the remainder of this notebook is to explore methods that are able to identify samples $x$ from the interval excursion set.\n",
    "\n",
    "Mathematically this is:\n",
    "$$\n",
    "x \\in \\mathbb{R}^n, \\quad a, b \\in \\mathbb{R}^m \\quad f: \\mathbb{R}^n \\mapsto \\mathbb{R}^m\\quad a < f(x) < b\n",
    "$$\n",
    "\n",
    "Solving this problem is more general than calculating:\n",
    "- the level set ($f(x) = c$)\n",
    "- superlevel set ($f(x) > c$)\n",
    "- sublevel set ($f(x) < c$)\n",
    "Howver, each can be formulated such that samples returned can approximate each of these types of level set for crafted values of $a, b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that a Gaussian random variable $y \\sim \\mathcal{N}(\\mu, \\sigma^2)$ lies in the interval $a < y < b$ is:\n",
    "$$\n",
    "P(a < y < b) = \\Phi\\left(\\frac{b - \\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)\n",
    "$$\n",
    "where $\\Phi(\\cdot)$ is the cumulative distribution function (CDF) of the standard normal distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Bayesian setting, this interval probability is used as a likelihood function. The posterior density for $x$ is then proportional to the product of the prior $p(x)$ and the probability that the model output $f(x)$ lies in the interval $a < y < b$:\n",
    "\n",
    "$$\n",
    "\n",
    "p(x \\mid a < f(x) < b) \\propto p(x) \\left[ \\Phi\\left(\\frac{b - \\mu(x)}{\\sigma(x)}\\right) - \\Phi\\left(\\frac{a - \\mu(x)}{\\sigma(x)}\\right) \\right]\n",
    "\n",
    "$$\n",
    "\n",
    "where $\\mu(x)$ and $\\sigma(x)$ are the mean and standard deviation of the model output at $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower, upper = 30_000, 40_000\n",
    "ies = IntervalExcursionSetCalibration(\n",
    "    gp,\n",
    "    parameters_range=simulator.parameters_range,\n",
    "    output_bounds={\"distance\": (lower, upper)},\n",
    "    output_names=simulator.output_names,\n",
    "    log_level=\"error\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC\n",
    "\n",
    "Default to use NUTS here but metropolis also can produce reasonable samples for low-dimensional parameter spaces as is the case in this epidemic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = ies.run_mcmc(\n",
    "    num_samples=1000,\n",
    "    warmup_steps=200,\n",
    "    num_chains=2,\n",
    "    sampler=\"nuts\",\n",
    "    # sampler=\"metropolis\",\n",
    "    model_kwargs={\"uniform_prior\": True}\n",
    ")\n",
    "az_mcmc = ies.to_arviz(mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = ies.posterior_predictive(mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.plot_samples(az_mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_data = ies.to_arviz(mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = az.plot_pair(az_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert emulator calibration samples\n",
    "def get_dist_and_plot(ies, data):\n",
    "    \"\"\"Convert and plot GetDist MCSamples from MCMC samples.\"\"\"\n",
    "    emu_data = ies.to_getdist(data, label=\"Emulator\")\n",
    "    emu_data.smooth_scale_1D = 0.8\n",
    "    g = plots.get_subplot_plotter()\n",
    "    g.triangle_plot([emu_data], filled=True)\n",
    "    plt.show()\n",
    "\n",
    "get_dist_and_plot(ies, mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Monte Carlo (SMC) with adaptive tempering\n",
    "\n",
    "The SMC implementation provides an alternative to MCMC approaches.\n",
    "\n",
    "It works by tempering the interval excursion set likelihood from 0 to 1 (i.e. sampling from the prior to the posterior), adaptively controlling steps to hit a target Effective Sample Size (ESS). We resample when ESS falls below the threshold. This converges to the exact target at temperature 1 without gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_data_smc = ies.run_smc(\n",
    "    n_particles=4000,\n",
    "    ess_target_frac=0.6,\n",
    "    move_steps=2,\n",
    "    rw_step=0.25,\n",
    "    seed=random_seed,\n",
    "    uniform_prior=True,\n",
    "    plot_diagnostics=True,\n",
    "    return_az_data=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = az.plot_pair(az_data_smc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(az_data_smc, az.InferenceData)\n",
    "ies.plot_samples(az_data_smc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dist_and_plot(ies, az_data_smc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History matching with interval excursion set likelihood\n",
    "\n",
    "This secion looks at using the current history matching workflow to generate samples from the interval excursion set. Note this approach is best for cases where either to cases where all output dimensions have specified intervals (such as 1D problem)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower = ies.y_lower.item()\n",
    "upper = ies.y_upper.item()\n",
    "midpoint = 0.5 * (lower + upper)\n",
    "difference = upper - lower\n",
    "# 100 observations in the interval to weight posterior towards interval\n",
    "observations = {\"distance\": lower + (upper - lower)*torch.rand(100)}\n",
    "\n",
    "hm = HistoryMatchingWorkflow(\n",
    "    simulator=simulator,\n",
    "    result=ae.best_result(),\n",
    "    observations={\n",
    "        \"distance\": (midpoint, (difference / 4 * 2)**2), # 2 * sigma = 0.05\n",
    "    },\n",
    "    threshold=1.0, # implausibility threshold in sigma units\n",
    "    train_x=x,\n",
    "    train_y=y,\n",
    "    log_level=\"error\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples in NROY space\n",
    "x_new = simulator.sample_inputs(10000)\n",
    "mean, variance = gp.predict_mean_and_variance(x_new)\n",
    "assert isinstance(variance, torch.Tensor)\n",
    "implausibility = hm.calculate_implausibility(mean, variance)\n",
    "x_star_nroy = hm.get_nroy(implausibility, x_new)\n",
    "ies.plot_samples(x_star_nroy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
