{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# probabilistic programming\n",
    "import pyro \n",
    "\n",
    "# MCMC plotting\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from getdist.arviz_wrapper import arviz_to_mcsamples\n",
    "from getdist import plots\n",
    "\n",
    "# autoemulate imports\n",
    "from autoemulate.simulations.epidemic import Epidemic\n",
    "from autoemulate.core.compare import AutoEmulate\n",
    "from autoemulate.calibration.bayes import BayesianCalibration\n",
    "from autoemulate.emulators import GaussianProcess\n",
    "\n",
    "# suppress warnings in notebook for readability\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "# random seed for reproducibility\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Epidemic simulation: run simulator and fit emulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.data.utils import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "pyro.set_rng_seed(random_seed)\n",
    "\n",
    "simulator = Epidemic(log_level=\"error\")\n",
    "x = simulator.sample_inputs(1000)\n",
    "y, _ = simulator.forward_batch(x)\n",
    "\n",
    "transmission_rate = x[:, 0]\n",
    "recovery_rate = x[:, 1]\n",
    "\n",
    "plt.scatter(transmission_rate, recovery_rate, c=y, cmap='viridis')\n",
    "plt.xlabel('Transmission rate (beta)')\n",
    "plt.ylabel('Recovery rate (gamma)')\n",
    "plt.colorbar(label=\"Peak infection rate\")\n",
    "plt.show()\n",
    "\n",
    "# Run AutoEmulate to find the best GP model\n",
    "from autoemulate.emulators.gaussian_process.exact import GaussianProcessRBF\n",
    "\n",
    "ae = AutoEmulate(\n",
    "    x, \n",
    "    y, \n",
    "    models=[GaussianProcessRBF],\n",
    "    model_params={},\n",
    "    log_level=\"error\", \n",
    ")\n",
    "\n",
    "gp = ae.best_result().model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set-up: identify an interval excursion set for $f(x)$\n",
    "\n",
    "The aim for the remainder of this notebook is to explore methods that are able to identify samples $x$ from the interval excursion set.\n",
    "\n",
    "Mathematically this is:\n",
    "$$\n",
    "x \\in \\mathbb{R}^n, \\quad a, b \\in \\mathbb{R}^m \\quad f: \\mathbb{R}^n \\mapsto \\mathbb{R}^m\\quad a < f(x) < b\n",
    "$$\n",
    "\n",
    "Solving this problem is more general than calculating:\n",
    "- the level set ($f(x) = c$)\n",
    "- superlevel set ($f(x) > c$)\n",
    "- sublevel set ($f(x) < c$)\n",
    "Howver, each can be formulated such that samples returned can approximate each of these types of level set for crafted values of $a, b$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The probability that a Gaussian random variable $y \\sim \\mathcal{N}(\\mu, \\sigma^2)$ lies in the interval $a < y < b$ is:\n",
    "$$\n",
    "P(a < y < b) = \\Phi\\left(\\frac{b - \\mu}{\\sigma}\\right) - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)\n",
    "$$\n",
    "where $\\Phi(\\cdot)$ is the cumulative distribution function (CDF) of the standard normal distribution.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the Bayesian setting, this interval probability is used as a likelihood function. The posterior density for $x$ is then proportional to the product of the prior $p(x)$ and the probability that the model output $f(x)$ lies in the interval $a < y < b$:\n",
    "\n",
    "$$\n",
    "\n",
    "p(x \\mid a < f(x) < b) \\propto p(x) \\left[ \\Phi\\left(\\frac{b - \\mu(x)}{\\sigma(x)}\\right) - \\Phi\\left(\\frac{a - \\mu(x)}{\\sigma(x)}\\right) \\right]\n",
    "\n",
    "$$\n",
    "\n",
    "where $\\mu(x)$ and $\\sigma(x)$ are the mean and standard deviation of the model output at $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.calibration.interval_excursion_set import IntervalExcursionSetCalibration\n",
    "\n",
    "lower, upper = 0.2, 0.225\n",
    "ies = IntervalExcursionSetCalibration(\n",
    "    gp,\n",
    "    parameters_range=simulator.parameters_range,\n",
    "    y_lower=torch.tensor([lower]),  # lower bound(s) per task\n",
    "    y_upper=torch.tensor([upper]),  # upper bound(s) per task\n",
    "    output_names=simulator.output_names,\n",
    "    log_level=\"error\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MCMC\n",
    "\n",
    "Default to use NUTS here but metropolis also can produce reasonable samples for low-dimensional parameter spaces as is the case in this epidemic model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc = ies.run_mcmc(\n",
    "    num_samples=1000,\n",
    "    warmup_steps=200,\n",
    "    num_chains=2,\n",
    "    sampler=\"nuts\",\n",
    "    # sampler=\"metropolis\",\n",
    "    model_kwargs={\"uniform_prior\": True}\n",
    ")\n",
    "az_mcmc = ies.to_arviz(mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.plot_samples(az_mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_data = ies.to_arviz(mcmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = az.plot_pair(az_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert emulator calibration samples\n",
    "def get_dist_and_plot(ies, data):\n",
    "    \"\"\"Convert and plot GetDist MCSamples from MCMC samples.\"\"\"\n",
    "    emu_data = ies.to_getdist(data, label=\"Emulator\")\n",
    "    emu_data.smooth_scale_1D = 0.8\n",
    "    g = plots.get_subplot_plotter()\n",
    "    g.triangle_plot([emu_data], filled=True)\n",
    "    plt.show()\n",
    "\n",
    "get_dist_and_plot(ies, mcmc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Monte Carlo (SMC) with adaptive tempering\n",
    "\n",
    "The SMC implementation provides an alternative to MCMC approaches.\n",
    "\n",
    "It works by tempering the interval excursion set likelihood from 0 to 1 (i.e. sampling from the prior to the posterior), adaptively controlling steps to hit a target Effective Sample Size (ESS). We resample when ESS falls below the threshold. This converges to the exact target at temperature 1 without gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_data_smc = ies.run_smc(\n",
    "    n_particles=4000,\n",
    "    ess_target_frac=0.6,\n",
    "    move_steps=2,\n",
    "    rw_step=0.25,\n",
    "    seed=random_seed,\n",
    "    uniform_prior=True,\n",
    "    plot_diagnostics=True,\n",
    "    return_az_data=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = az.plot_pair(az_data_smc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert isinstance(az_data_smc, az.InferenceData)\n",
    "ies.plot_samples(az_data_smc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dist_and_plot(ies, az_data_smc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History matching with interval excursion set likelihood\n",
    "\n",
    "This secion looks at using the current history matching workflow to generate samples from the interval excursion set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.calibration.history_matching import HistoryMatchingWorkflow\n",
    "import numpy as np\n",
    "\n",
    "lower = ies.y_lower.item()\n",
    "upper = ies.y_upper.item()\n",
    "midpoint = 0.5 * (lower + upper)\n",
    "difference = upper - lower\n",
    "# 100 observations in the interval to weight posterior towards interval\n",
    "observations = {\"infection_rate\": lower + (upper - lower)*torch.rand(100)}\n",
    "\n",
    "hm = HistoryMatchingWorkflow(\n",
    "    simulator=simulator,\n",
    "    result=ae.best_result(),\n",
    "    observations={\"infection_rate\": (midpoint, (difference / 4 * 2)**2)}, # 2 * sigma = 0.05\n",
    "    threshold=1.0, # implausibility threshold in sigma units\n",
    "    train_x=x,\n",
    "    train_y=y,\n",
    "    log_level=\"error\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples in NROY space\n",
    "x_new = simulator.sample_inputs(10000)\n",
    "mean, variance = gp.predict_mean_and_variance(x_new)\n",
    "assert isinstance(variance, torch.Tensor)\n",
    "implausibility = hm.calculate_implausibility(mean, variance)\n",
    "x_star_nroy = hm.get_nroy(implausibility, x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.plot_samples(x_star_nroy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with a BayesianCalibration approach\n",
    "\n",
    "\n",
    "\n",
    "This final section explores using the current `BayesianCalibration` approach with a Gaussian-noise observation probabilistic model.\n",
    "\n",
    "\n",
    "\n",
    "Here, we generate a set of synthetic observations that are chosen to lie within the target interval. These are not real data, but are constructed to represent the interval constraint as if they were observed values. We then use a Gaussian likelihood with mean and variance derived from the emulator, treating these synthetic values as if they were real observations.\n",
    "\n",
    "\n",
    "Mathematically, for synthetic observations $y_1, \\ldots, y_N$ (all in the interval) and model output $f(x)$, the likelihood is:\n",
    "\n",
    "$$\n",
    "\n",
    "p(y_1, \\ldots, y_N \\mid x) = \\prod_{i=1}^N \\mathcal{N}(y_i \\mid \\mu(x), \\sigma^2(x) + \\tau^2 + \\gamma^2)\n",
    "\n",
    "$$\n",
    "\n",
    "where $\\mu(x)$ and $\\sigma^2(x)$ are the emulator's predictive mean and variance at $x$, $\\tau^2$ is the observation noise variance, and $\\gamma^2$ is an additional variance chosen to represent model discrepancy and imperfections. The set of variances included to represent uncertainty are similar to those in history matching.\n",
    "\n",
    "The posterior is then:\n",
    "\n",
    "$$\n",
    "\n",
    "p(x \\mid y_1, \\ldots, y_N) \\propto p(x) \\prod_{i=1}^N \\mathcal{N}(y_i \\mid \\mu(x), \\sigma^2(x) + \\tau^2)\n",
    "\n",
    "$$\n",
    "\n",
    "where $p(x)$ is the prior over parameters (uniform in the `BayesianCalibration` method here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BayesianCalibration(\n",
    "    gp, \n",
    "    simulator.parameters_range, \n",
    "    observations, \n",
    "    observation_noise=0.1,\n",
    "    model_uncertainty=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_bc = bc.run_mcmc(\n",
    "    warmup_steps=250, \n",
    "    num_samples=500,\n",
    "    num_chains=2    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "az_mcmc_bc = bc.to_arviz(mcmc_bc)\n",
    "az.plot_pair(az_mcmc_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.plot_samples(mcmc_bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_dist_and_plot(ies, az_mcmc_bc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
