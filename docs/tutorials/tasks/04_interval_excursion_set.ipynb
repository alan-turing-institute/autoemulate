{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# probabilistic programming\n",
    "import pyro \n",
    "\n",
    "# MCMC plotting\n",
    "import arviz as az\n",
    "import matplotlib.pyplot as plt\n",
    "from getdist.arviz_wrapper import arviz_to_mcsamples\n",
    "from getdist import plots\n",
    "\n",
    "# autoemulate imports\n",
    "from autoemulate.simulations.epidemic import Epidemic\n",
    "from autoemulate.core.compare import AutoEmulate\n",
    "from autoemulate.calibration.bayes import BayesianCalibration\n",
    "from autoemulate.emulators import GaussianProcess\n",
    "\n",
    "# suppress warnings in notebook for readability\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "# ignore warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "os.environ[\"PYTHONWARNINGS\"] = \"ignore\"\n",
    "\n",
    "# random seed for reproducibility\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.data.utils import set_random_seed\n",
    "set_random_seed(random_seed)\n",
    "pyro.set_rng_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Epidemic(log_level=\"error\")\n",
    "x = simulator.sample_inputs(1000)\n",
    "y, _ = simulator.forward_batch(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transmission_rate = x[:, 0]\n",
    "recovery_rate = x[:, 1]\n",
    "\n",
    "plt.scatter(transmission_rate, recovery_rate, c=y, cmap='viridis')\n",
    "plt.xlabel('Transmission rate (beta)')\n",
    "plt.ylabel('Recovery rate (gamma)')\n",
    "plt.colorbar(label=\"Peak infection rate\")\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_beta = 0.3\n",
    "true_gamma = 0.15 \n",
    "\n",
    "# simulator expects inputs of shape [1, number of inputs]\n",
    "params = torch.tensor([true_beta, true_gamma]).view(1, -1)\n",
    "true_infection_rate = simulator.forward(params)\n",
    "assert isinstance(true_infection_rate, torch.Tensor)\n",
    "\n",
    "n_obs = 100\n",
    "stdev = 0.05\n",
    "noise = torch.normal(mean=0, std=stdev, size=(n_obs,))\n",
    "observed_infection_rates = true_infection_rate[0] + noise\n",
    "\n",
    "observations = {\"infection_rate\": observed_infection_rates}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run AutoEmulate to find the best GP model\n",
    "from autoemulate.emulators.gaussian_process.exact import GaussianProcessRBF\n",
    "\n",
    "\n",
    "ae = AutoEmulate(\n",
    "    x, \n",
    "    y, \n",
    "    models=[GaussianProcessRBF],\n",
    "    model_params={},\n",
    "    log_level=\"error\", \n",
    ")\n",
    "\n",
    "gp = ae.best_result().model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem set-up: identify an interval excursion set for $f(x)$\n",
    "\n",
    "The aim for the remainder of this notebook is to explore methods that are able to identify samples $x$ from the interval excursion set.\n",
    "\n",
    "Mathematically this is:\n",
    "$$\n",
    "x \\in \\mathbb{R}^n, \\quad a, b \\in \\mathbb{R}^m \\quad f: \\mathbb{R}^n \\mapsto \\mathbb{R}^m\\quad a < f(x) < b\n",
    "$$\n",
    "\n",
    "Solving this problem is more general than calculating:\n",
    "- the level set ($f(x) = c$)\n",
    "- superlevel set ($f(x) > c$)\n",
    "- sublevel set ($f(x) < c$)\n",
    "Howver, each can be formulated such that samples returned can approximate each of these types of level set for crafted values of $a, b$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.calibration.interval_excursion_set import IntervalExcursionSetCalibration\n",
    "\n",
    "ies = IntervalExcursionSetCalibration(\n",
    "    gp,\n",
    "    parameter_range=simulator.parameters_range,\n",
    "    y_lower=torch.tensor([0.3]),  # lower bound(s) per task\n",
    "    y_upper=torch.tensor([0.6]),  # upper bound(s) per task\n",
    "    y_labels=[\"infection_rate\"],\n",
    "    log_level=\"error\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run MCMC\n",
    "mcmc = ies.run_mcmc(num_samples=1000, warmup_steps=200, num_chains=2, sampler=\"metropolis\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.plot_samples(mcmc.get_samples()[\"x_star\"], mcmc.num_samples * mcmc.num_chains)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Monte Carlo (SMC) with adaptive tempering\n",
    "\n",
    "SMC is a further alternative to importance sampling that might be expected to scale to higher dimensions slightly better.\n",
    "\n",
    "Temper the band likelihood from 0 to 1, adaptively controlling steps to hit a target Effective Sample Size (ESS). We resample when ESS falls below the threshold. This converges to the exact target at temperature 1 without gradients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_smc, smc_w, smc_betas, smc_ess, smc_unique = ies.run_smc(\n",
    "    n_particles=4000, ess_target_frac=0.6, move_steps=2, rw_step=0.25, seed=random_seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.plot_samples(x_smc, x_smc.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostic plots\n",
    "plt.figure(figsize=(5,4))\n",
    "plt.scatter(smc_particles[:,0].cpu(), smc_particles[:,1].cpu(), s=4, alpha=0.4, c='tab:orange')\n",
    "plt.title(f'SMC particles (final), unique={smc_unique}/{smc_particles.shape[0]}')\n",
    "plt.xlabel('x1'); plt.ylabel('x2'); plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(smc_betas.cpu().numpy(), '-o', ms=3)\n",
    "plt.ylabel('beta'); plt.xlabel('step'); plt.title('Temperatures')\n",
    "plt.tight_layout()\n",
    "\n",
    "plt.figure(figsize=(6,3))\n",
    "plt.plot(smc_ess.cpu().numpy(), '-o', ms=3)\n",
    "plt.ylabel('ESS'); plt.xlabel('step'); plt.title('ESS over steps')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### History matching with multi-task band likelihood\n",
    "\n",
    "This secion looks at using the current history matching workflow to generate samples from the excursion set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.calibration.history_matching import HistoryMatchingWorkflow\n",
    "import numpy as np\n",
    "\n",
    "lower = y_band_low.item()\n",
    "upper = y_band_high.item()\n",
    "midpoint = 0.5 * (lower + upper)\n",
    "difference = upper - lower\n",
    "observations = {\"infection_rate\": lower + (upper - lower)*torch.rand(100)}\n",
    "\n",
    "hm = HistoryMatchingWorkflow(\n",
    "    simulator=simulator,\n",
    "    result=ae.best_result(),\n",
    "    observations={\"infection_rate\": (midpoint, (difference / 4 * 2)**2)}, # 2 * sigma = 0.05\n",
    "    threshold=1.0, # implausibility threshold in sigma units\n",
    "    train_x=x,\n",
    "    train_y=y,\n",
    "    log_level=\"error\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get samples in NROY space\n",
    "x_new = simulator.sample_inputs(10000)\n",
    "mean, variance = gp.predict_mean_and_variance(x_new)\n",
    "assert isinstance(variance, torch.Tensor)\n",
    "implausibility = hm.calculate_implausibility(mean, variance)\n",
    "x_star_nroy = hm.get_nroy(implausibility, x_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.plot_samples(x_star_nroy, x_star_nroy.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare with a BayesianCalibration approach\n",
    "\n",
    "This section looks at using the current `BayesianCalibration` approach with a Gaussian-noise observation probabilistic model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bc = BayesianCalibration(\n",
    "    gp, \n",
    "    simulator.parameters_range, \n",
    "    observations, \n",
    "    observation_noise=0.1,\n",
    "    model_uncertainty=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run MCMC using the NUTS sampler. The `BayesianCalibration` class uses Pyro under the hood. Below we use `pyro.set_rng_seed` to ensure reproducibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_bc = bc.run_mcmc(\n",
    "    warmup_steps=250, \n",
    "    num_samples=500,\n",
    "    num_chains=2    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to required format for plotting\n",
    "x_post_bc = torch.hstack([\n",
    "    mcmc_bc.get_samples()[\"beta\"].reshape(-1, 1),\n",
    "    mcmc_bc.get_samples()[\"gamma\"].reshape(-1, 1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ies.plot_samples(x_post_bc, x_post_bc.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
