{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality reduction\n",
    "\n",
    "### Overview\n",
    "\n",
    "Sometimes an emulator performs better when the input and/or the output dimensionality is reduced. In this example, we show how one can specify dimensionality reduction methods to be used in combination with the emulators tested by AutoEmulate.\n",
    "\n",
    "###  Reaction-Diffusion example\n",
    "\n",
    "We train an emulator to generate solutions to a 2D parameterized reaction-diffusion problem governed by the following partial differential equations:\n",
    "\n",
    "$$\n",
    "\\dot{u} = (1 - (u^2 + v^2)) u + \\beta (u^2 + v^2) v + d (u_{xx} + u_{yy}),\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\dot{v} = -\\beta (u^2 + v^2) u + (1 - (u^2 + v^2)) v + d (v_{xx} + v_{yy}),\n",
    "$$\n",
    "\n",
    "where:\n",
    "\n",
    "- $ u $ and $ v $ are the concentrations of two species,\n",
    "- $ \\beta $ and $ d $ control the reaction and diffusion terms.\n",
    "\n",
    "This system exhibits complex spatio-temporal dynamics such as spiral waves.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt \n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from autoemulate.simulations.reaction_diffusion import ReactionDiffusion\n",
    "from autoemulate.datasets import fetch_data\n",
    "\n",
    "save = False\n",
    "train = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1: Data generation\n",
    "\n",
    "Data are computed using a numerical [_simulator_](https://github.com/dynamicslab/pysindy/blob/master/examples/10_PDEFIND_examples.ipynb) using Fourier spectral method.\n",
    "The simulator takes two inputs: the reaction parameter $\\beta$ and the diffusion parameter $d$.\n",
    "\n",
    "We sample 50 sets of inputs `X` using Latin Hypercube sampling and run the simulator for those inputs to get the solutions `Y`. Below you can either run the simulator or load data that has already been simulated.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 50\n",
    "n = 50\n",
    "sim = ReactionDiffusion(n=n, T=10)\n",
    "X = sim.sample_inputs(n_samples)\n",
    "\n",
    "if train:\n",
    "    data_folder =  \"../data/reactiondiffusion1/processed\" \n",
    "    if not os.path.exists(data_folder):\n",
    "        os.makedirs(data_folder)  \n",
    "    X_file = os.path.join(data_folder, \"parameters.csv\")\n",
    "    Y_file = os.path.join(data_folder, \"outputs.csv\")\n",
    "\n",
    "\n",
    "    # Run the simulator to generate data \n",
    "    # Simulator returns flattened species U and V\n",
    "    UV, _ = sim.forward_batch(X)\n",
    "\n",
    "    # Let's consider as output the concentration of species U\n",
    "    m = int(UV.shape[1] / 2)\n",
    "    Y = UV[:, :m]\n",
    "\n",
    "    if save:\n",
    "        # Save the data\n",
    "        pd.DataFrame(X).to_csv(X_file, index=False)\n",
    "        pd.DataFrame(Y).to_csv(Y_file, index=False)\n",
    "else:\n",
    "    # Load the data\n",
    "    X, Y = fetch_data('reactiondiffusion1')\n",
    "\n",
    "print(f\"shapes: input X: {X.shape}, output Y: {Y.shape}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`X` and `Y` are matrices where each row represents one run of the simulation. In the input matrix `X` the two columns indicate the input parameters (reaction $\\beta$ and diffusion $d$ parameters, respetively).\n",
    "In the output matrix `Y` each column indicates a spatial location where the solution (i.e. the concentration of $u$ at final time $T=10$) is computed. <br>\n",
    "We consider a 2D spatial grid of $50\\times 50$ points, therefore each row of `Y` corresponds to a 2500-dimensional vector!\n",
    "\n",
    "Letâ€™s now plot the simulated data to see what the reaction-diffusion pattern looks like.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,4.5))\n",
    "for param in range(3):\n",
    "  plt.subplot(1,3,1+param)\n",
    "  plt.imshow(Y[param].reshape(n,n), interpolation='bilinear')\n",
    "  plt.axis('off')\n",
    "  plt.xlabel('x', fontsize=12)\n",
    "  plt.ylabel('y')\n",
    "  plt.title(r'$\\beta = {:.2f}, d = {:.2f}$'.format(X[param][0], X[param][1]), fontsize=12)\n",
    "  plt.colorbar(fraction=0.046)\n",
    "plt.suptitle('2D solutions to the reaction-diffusion system for different parameters', fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2: Fit an emulator on a subset of the data\n",
    "\n",
    "Below we pass a sequence of `x_transforms` and `y_transforms` to `AutoEmulate`. In this example we apply PCA to the simulation output and train a Gaussian Process emulator on this reduced problem space. This is often more efficient for high dimensional problems.\n",
    "\n",
    "Note that the transforms are specified as a list of lists. This enables users to specify different transform combinations (each a list) to test with all the emulators. The transforms can be any subclass of `torch.distributions.Transform` - here we demonstrate how to flatten the data with `ReshapeTransform`. We also make use of `AutoEmulate` provided transforms to standardize the data before dimensionality reduction with PCA. In addition to dimensionality reduction with PCA, `AutoEmulate` also has an option to use Variational Autoencoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.core.compare import AutoEmulate\n",
    "from autoemulate.transforms import *\n",
    "from torch.distributions.transforms import ReshapeTransform\n",
    "import torch \n",
    "\n",
    "# Convert to tensors\n",
    "x, y = torch.Tensor(X).float(), torch.Tensor(Y).float().reshape(-1, n, n)\n",
    "\n",
    "# Split into train/test data\n",
    "test_idx = [np.array([13, 39, 30, 45, 17, 48, 26, 25, 32, 19])]\n",
    "train_idx = np.setdiff1d(np.arange(len(x)), test_idx)\n",
    "\n",
    "# Run AutoEmulate\n",
    "ae = AutoEmulate(\n",
    "    x[train_idx], \n",
    "    y[train_idx],\n",
    "    models=[\"GaussianProcess\"],\n",
    "    x_transforms_list=[[StandardizeTransform()]],\n",
    "    y_transforms_list=[[\n",
    "        ReshapeTransform((n, n), (n * n,)), # include torch transform to flatten first\n",
    "        StandardizeTransform(),\n",
    "        PCATransform(n_components=16),\n",
    "        StandardizeTransform()\n",
    "    ]],\n",
    "    # fewer bootstraps to reduce computation time, though more uncertainty on test score\n",
    "    n_bootstraps=None,\n",
    "    log_level=\"error\",\n",
    "    model_params={\"posterior_predictive\": True},\n",
    "    transformed_emulator_params={\n",
    "        \"full_covariance\": False,\n",
    "        \"output_from_samples\": False\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarise the results across the models considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.summarise().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get best performing emulator and fit on all training data with best model class reinitialized and refitted on all the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "em = ae.fit_from_reinitialized(x[train_idx], y[train_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3: Test predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get predictions for the full dataset\n",
    "y_true = y[test_idx].numpy()\n",
    "y_pred_dis = em.predict(x[test_idx])\n",
    "y_pred, y_var_pred = em.predict_mean_and_variance(x[test_idx])\n",
    "\n",
    "y_pred, y_std_pred = y_pred.numpy(), y_var_pred.sqrt().numpy()\n",
    "print(\"Prediction distribution shape:\", y_pred.shape, y_std_pred.shape)\n",
    "print(\"Mean shape:\", y_pred.shape)\n",
    "print(\"Std shape:\", y_std_pred.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results for some unseen (test) parameter instances\n",
    "params_test = [0,1,2,3]\n",
    "\n",
    "for param_test in params_test:\n",
    "  plt.figure(figsize=(20,4.5))\n",
    "  plt.subplot(1,4,1)\n",
    "  plt.imshow(y_true[param_test], interpolation='bilinear')\n",
    "  plt.axis('off')\n",
    "  plt.xlabel('x', fontsize=12)\n",
    "  plt.ylabel('y')\n",
    "  plt.title('True solution (simulator)', fontsize=12)\n",
    "  plt.colorbar(fraction=0.046)\n",
    "\n",
    "  plt.subplot(1,4,2)\n",
    "  plt.imshow(y_pred[param_test], interpolation='bilinear')\n",
    "  plt.axis('off')\n",
    "  plt.xlabel('x', fontsize=12)\n",
    "  plt.ylabel('y')\n",
    "  plt.title('Prediction (emulator)', fontsize=12)\n",
    "  plt.colorbar(fraction=0.046)\n",
    "\n",
    "  plt.subplot(1,4,3)\n",
    "  plt.imshow(y_std_pred[param_test], cmap = 'bwr', interpolation='bilinear', vmax = np.max(y_std_pred[params_test]))\n",
    "  plt.axis('off')\n",
    "  plt.xlabel('x', fontsize=12)\n",
    "  plt.ylabel('y')\n",
    "  plt.title('Standard Deviation (emulator)', fontsize=12)\n",
    "  plt.colorbar(fraction=0.046)\n",
    "\n",
    "  plt.subplot(1,4,4)\n",
    "  plt.imshow(np.abs(y_pred[param_test] - y_true[param_test]), cmap = 'bwr', interpolation='bilinear')\n",
    "  plt.axis('off')\n",
    "  plt.xlabel('x', fontsize=12)\n",
    "  plt.ylabel('y')\n",
    "  plt.title('Absolute error', fontsize=12)\n",
    "  plt.colorbar(fraction=0.046)\n",
    "\n",
    "  # plt.suptitle(r'Results for test parameters: $\\beta = {:.2f}, d = {:.2f}$'.format(X[em.test_idxs][param_test][0], X[em.test_idxs][param_test][1]), fontsize=12)\n",
    "  plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "autoemulate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
