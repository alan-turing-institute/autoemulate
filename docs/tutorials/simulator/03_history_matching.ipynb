{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.emulators import GaussianProcess\n",
    "from autoemulate.core.compare import AutoEmulate\n",
    "from autoemulate.simulations.epidemic import Epidemic\n",
    "from autoemulate.calibration.history_matching import HistoryMatchingWorkflow\n",
    "from autoemulate.calibration.history_matching_dashboard import HistoryMatchingDashboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# History Matching workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `HistoryMatching` calibration method can be a useful way to iteratively decide which simulations to run to generate data refine the emulator on. The `HistoryMatchingWorkflow` implements this iterative sample-predict-refit workflow. Each time it is run:\n",
    "- parameters are sampled from the not ruled out yet (NROY) space\n",
    "- an emulator is used in combination with `HistoryMatching` to score the implausability of the samples\n",
    "- simulations are run for a subset of the NROY samples\n",
    "- the emulator is refit given the newly simulated data\n",
    "\n",
    "\n",
    "In this tutorial, we demonstrate how to implement this simulator in the loop workflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Simulate data and train an emulator\n",
    "\n",
    "In this example, we'll use the `Epidemic` simulator, which returns the peak infection rate given two input parameters, `beta`(the transimission rate per day) and `gamma` (the recovery rate per day)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulator = Epidemic(log_level=\"error\")\n",
    "x = simulator.sample_inputs(500, random_seed=random_seed)\n",
    "y = simulator.forward_batch(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this tutorial, we will restrict the model choice to `GaussianProcess`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEmulate(x, y, models=[GaussianProcess], log_level=\"error\", random_seed=random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can verify that the fitted emulator performs well on both the train and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.summarise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ae.best_result().model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Calibrate\n",
    "\n",
    "To instantiate the `HistoryMatchingWorkflow` object, we need an observed mean and, optionally, variance for each simulator output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "observations = {\"infection_rate\": (0.3, 0.05)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also pass the fitted emulator and the simulator to the `HistoryMatchingWorkflow`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmw = HistoryMatchingWorkflow(\n",
    "    simulator=simulator,\n",
    "    emulator=model,\n",
    "    observations=observations,\n",
    "    threshold=3.0,\n",
    "    train_x=x,\n",
    "    train_y=y, \n",
    "    random_seed=random_seed\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `run` method implements the iterative sample-predict-refit workflow:\n",
    "- sample `n_test_samples` to test from the not ruled out yet (NROY) space\n",
    "- use emulator to filter out implausible samples and update the NROY space\n",
    "- run `n_simulations` predictions for the sampled parameters using the simulator\n",
    "- refit the emulator using the simulated data\n",
    "\n",
    "The `HistoryMatchingWorkflow` object maintains and updates the internal state each time `run()` is called so the full workflow can be run over a number of iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_parameters, impl_scores = hmw.run(n_simulations=20, n_test_samples=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualise results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard = HistoryMatchingDashboard(\n",
    "    samples=test_parameters,\n",
    "    impl_scores=impl_scores,\n",
    "    param_names=simulator.param_names,  \n",
    "    output_names=simulator.output_names, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dashboard.display()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
