{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Adding emulators\n",
    "\n",
    "In addition to providing a library of core emulators, AutoEmulate is designed to be easily extensible. This tutorial walks you through the steps of adding new emulators to the library. We cover two scenarios: adding new Gaussian Process kernels and adding entirely new models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 1. Adding Gaussian Process kernels\n",
    "\n",
    "Gaussian Processes (GPs) are primarily defined by their kernel functions, which determine the covariance structure of the data. AutoEmulate includes several built-in GP kernels:\n",
    "- Radial Basis Function (RBF)\n",
    "- Matern 3/2\n",
    "- Matern 5/2\n",
    "- Rational Quadratic (RQ)\n",
    "- Linear\n",
    "\n",
    "You can easily create new kernels by composing any two or more of these existing kernels. For example, you might want to create a kernel that combines the RBF and Linear kernels to capture both smooth variations and linear trends in your data.\n",
    "\n",
    "In AutoEmulate, each kernel is defined by an initialisation function that takes as inputs the number of data input features and the number of output features. Below we define a custom kernel function following this pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.emulators.gaussian_process.kernel import rbf_kernel, linear_kernel\n",
    "\n",
    "def rbs_plus_linear_kernel(n_features, n_outputs):\n",
    "    \"\"\"\n",
    "    Example of a custom kernel function that combines RBF and linear kernels.\n",
    "    \"\"\"\n",
    "    return rbf_kernel(n_features, n_outputs) + linear_kernel(n_features, n_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3",
   "metadata": {},
   "source": [
    "Once this function has been defined, you can create a new GP emulator class using the `create_gp_subclass` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.emulators.gaussian_process.exact import GaussianProcess, create_gp_subclass\n",
    "\n",
    "GaussianProcessRBFandLinear = create_gp_subclass(\n",
    "   \"GaussianProcessRBFandLinear\", \n",
    "   GaussianProcess, \n",
    "   # the custom kernel function goes here\n",
    "   covar_module_fn=rbs_plus_linear_kernel,\n",
    "   auto_register=True,\n",
    "   overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "Now we can tell AutoEmulate to use the new GP class by passing it to the `models` argument when initialising an `AutoEmulate` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate import AutoEmulate\n",
    "import torch\n",
    "\n",
    "# create some example data\n",
    "x = torch.linspace(0, 1, 100).unsqueeze(-1)\n",
    "y = torch.sin(2 * 3.14 * x) + 0.1 * torch.randn_like(x)\n",
    "\n",
    "ae = AutoEmulate(x, y, models=[GaussianProcessRBFandLinear])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.summarise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "## 2. Adding new models\n",
    "\n",
    "It is also possible to add entirely new models to AutoEmulate. AutoEmulate has a base `Emulator` class that handles most of the general functionality required for training and prediction. To implement a new emulator, one must simply subclass `Emulator` and implement the abstract methods (`_fit`, `_predict` and `is_multioutput`), `get_tune_params` to enable model tuning, as well any model specific functionality and initialisations.\n",
    "\n",
    "Since AutoEmulate supports a variety of models, there are additional `Emulator` subclasses that handle specific functionality for each model type:\n",
    "- `PytorchBackend` for PyTorch models\n",
    "- `SklearnBackend` for scikit-learn models\n",
    "- `GaussianProcess` for exact Gaussian Process implementations\n",
    "- `Ensemble` for ensemble models\n",
    "\n",
    "Subclassing one of these directly has slightly different requirements. For example, when subclassing `PytorchBackend` or `GaussianProcess`, one must implement the `forward` method to define the model's forward pass.\n",
    "\n",
    "There are also some static methods that should be implemented to provide metadata about the model, such as `is_multioutput` and `get_tune_params`.\n",
    "\n",
    "Below demonstrates adding a simple feedforward neural network (FNN) using PyTorch. The new class `SimpleFNN` subclasses `PytorchBackend`, which already handles fitting and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autoemulate.core.device import TorchDeviceMixin\n",
    "from autoemulate.emulators.base import PyTorchBackend\n",
    "from autoemulate.emulators import register\n",
    "import torch.nn as nn\n",
    "\n",
    "@register(overwrite=True) # decorate to register the emulator, optionally overwrite existing registration\n",
    "class SimpleFNN(PyTorchBackend):\n",
    "    def __init__(\n",
    "        self, \n",
    "        x, \n",
    "        y,\n",
    "        hidden_dim=64,\n",
    "        device = None,\n",
    "    ):\n",
    "        TorchDeviceMixin.__init__(self, device=device)\n",
    "        nn.Module.__init__(self)\n",
    "        \n",
    "        input_dim = x.shape[1]\n",
    "        output_dim = y.shape[1] if len(y.shape) > 1 else 1\n",
    "        layers = []\n",
    "        layers.append(nn.Linear(input_dim, hidden_dim, device=self.device))\n",
    "        layers.append(nn.ReLU())\n",
    "        layers.append(nn.Linear(hidden_dim, output_dim, device=self.device))\n",
    "        self.model = nn.Sequential(*layers)\n",
    "        self.optimizer = self.optimizer_cls(self.model.parameters(), lr=self.lr)  # type: ignore[call-arg] since all optimizers include lr\n",
    "        self.scheduler = None\n",
    "        self.to(self.device)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "        \n",
    "    @staticmethod\n",
    "    def is_multioutput():\n",
    "        return True\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_tune_params():\n",
    "        return {\n",
    "            \"hidden_dim\": [32, 64, 128]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae = AutoEmulate(x, y, models=[SimpleFNN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "ae.summarise()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The emulator can also be reinitialized and fitted on a dataset having been registered with AutoEmulate using the `@register` decorator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "em = ae.fit_from_reinitialized(x, y)\n",
    "print(em.model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
